{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexmoed/MasterClass/blob/3D-Pointnet%2B%2B/PointNet_Classification_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pnOKJBB5xk79"
      },
      "outputs": [],
      "source": [
        " # !git clone https://github.com/karol-202/direct-3dgs-segmentation \"/content/drive/MyDrive/3dgs/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8Ax15U0J8pB",
        "outputId": "f4fc9044-1242-4877-c81c-721da5cfe0d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "#change the directory to the correct spot on google drive\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNHhvtbP9qwt"
      },
      "source": [
        "#Train a semantic segmentation model for 3D Gaussian Splats\n",
        "# Modified from :\n",
        "# Yanx27 (2019). PointNet_Pointnet2_pytorch [online].\n",
        "# [Accessed 2024]. Available from: \"https://github.com/yanx27/Pointnet_Pointnet2_pytorch\"\n",
        "# Based on research from:\n",
        "# Jurski, K. (2024). Semantic 3D segmentation of 3D Gaussian Splats: Assessing existing\n",
        "# point cloud segmentation techniques on semantic segmentation of synthetic 3D Gaussian\n",
        "# Splats scenes. Bachelor's Thesis, Delft University of Technology.\n",
        "# Extended implementation: \"https://github.com/karol-202/direct-3dgs-segmentation\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7gebjNX7XYg"
      },
      "source": [
        "##PointNet ++ for Gaussian splats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJCG4e5x7cQe"
      },
      "source": [
        "Installing depencencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciTW75Hh_6_w",
        "outputId": "d320093f-9b47-4330-e573-5f1fc3206ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plyfile\n",
            "  Downloading plyfile-1.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from plyfile) (2.0.2)\n",
            "Downloading plyfile-1.1-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: plyfile\n",
            "Successfully installed plyfile-1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install plyfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlodEOZnyQWS",
        "outputId": "2c4d9993-94ed-4257-cdf8-12ebb102b0d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "\u001b[33mWARNING: Skipping pytorch3d as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#Uninstall any versions of pytorch3d\n",
        "!pip uninstall -y torch torchvision torchaudio pytorch3d\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egDDaEHnyT9X",
        "outputId": "b520c278-8d9f-49b6-dbcb-976ccc8ff8e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/nightly/cu121\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/torch-2.6.0.dev20241112%2Bcu121-cp311-cp311-linux_x86_64.whl (768.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.0/768.0 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/torchvision-0.20.0.dev20241112%2Bcu121-cp311-cp311-linux_x86_64.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/torchaudio-2.5.0.dev20241112%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m128.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-triton==3.1.0+cf34004b8a (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/pytorch_triton-3.1.0%2Bcf34004b8a-cp311-cp311-linux_x86_64.whl (239.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.7/239.7 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: pytorch-triton, nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 pytorch-triton-3.1.0+cf34004b8a torch-2.6.0.dev20241112+cu121 torchaudio-2.5.0.dev20241112+cu121 torchvision-0.20.0.dev20241112+cu121\n"
          ]
        }
      ],
      "source": [
        "#Run this exact version of torch vision others dont seem to work with pytorch 3d\n",
        "!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSilur4IzHSu",
        "outputId": "26dc4d38-dbb3-44ff-d51f-aac2e239536d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (3.31.6)\n",
            "Collecting cmake\n",
            "  Downloading cmake-4.0.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Downloading cmake-4.0.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja, cmake\n",
            "  Attempting uninstall: cmake\n",
            "    Found existing installation: cmake 3.31.6\n",
            "    Uninstalling cmake-3.31.6:\n",
            "      Successfully uninstalled cmake-3.31.6\n",
            "Successfully installed cmake-4.0.2 ninja-1.11.1.4\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.0.2)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.2.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath) (4.13.2)\n",
            "Collecting portalocker (from iopath)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=8a5d1dc5dc09f02fe86d9b9d18076d920f5b1af0ea954f7945b5dba2e7b534a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=b5f6305004208cfc27caa8283f1a9334e555ab8c9ec5b1f192ecbd8e5cde4f0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.1.1 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install -U cmake ninja\n",
        "!pip install fvcore iopath\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNViPp8JzCT5",
        "outputId": "5acff44a-c5f1-4096-a73f-7772d274ff8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/pytorch3d.git@stable\n",
            "  Cloning https://github.com/facebookresearch/pytorch3d.git (to revision stable) to /tmp/pip-req-build-ma08u0e0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorch3d.git /tmp/pip-req-build-ma08u0e0\n",
            "  Running command git checkout -q 75ebeeaea0908c5527e7b1e305fbc7681382db47\n",
            "  Resolved https://github.com/facebookresearch/pytorch3d.git to commit 75ebeeaea0908c5527e7b1e305fbc7681382db47\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.11/dist-packages (from pytorch3d==0.7.8) (0.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from iopath->pytorch3d==0.7.8) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath->pytorch3d==0.7.8) (4.13.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath->pytorch3d==0.7.8) (3.1.1)\n",
            "Building wheels for collected packages: pytorch3d\n"
          ]
        }
      ],
      "source": [
        "#Install the newest stable version of pytorch3d It takes awhile this is normal\n",
        "!pip install \"git+https://github.com/facebookresearch/pytorch3d.git@stable\"\n",
        "#It will get stuck on building wheels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDUU4_c1xtCO"
      },
      "outputs": [],
      "source": [
        "import pytorch3d\n",
        "print(pytorch3d.__version__)\n",
        "#make sure its the following version\n",
        "#0.7.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZX2ATSaRn5-"
      },
      "outputs": [],
      "source": [
        "!pip install trimesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBmJqHSvu1p5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTYwJLMKRA0k"
      },
      "outputs": [],
      "source": [
        "# Partially from: https://github.com/yanx27/Pointnet_Pointnet2_pytorch\n",
        "import argparse\n",
        "import os\n",
        "import datetime\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import importlib\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "import torch.utils.data.sampler as sampler\n",
        "\n",
        "# Add this patch to fix NumPy issue with PyTorch DataLoader\n",
        "import torch.utils.data.sampler as sampler\n",
        "# Add this patch to fix NumPy issue with PyTorch DataLoader\n",
        "import torch.utils.data.sampler as sampler\n",
        "\n",
        "%cd /content/drive/MyDrive/3dgs\n",
        "#Change to your repo\n",
        "\n",
        "# Custom imports\n",
        "from data_utils.extra_feature import ExtraFeature\n",
        "from datasets.base_3dgs_dataset import Base3DGSDataset\n",
        "from datasets.composed_mesh_dataset import ComposedMeshDataset\n",
        "from datasets.composed_3dgs_dataset import Composed3DGSDataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs6iXDvz_R3l"
      },
      "source": [
        "# Define paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RngAxBqksrqB"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "BASE_DIR = \"/content/drive/MyDrive/3dgs\"  # Path for Google Colab\n",
        "experiment_dir = BASE_DIR\n",
        "ROOT_DIR = BASE_DIR\n",
        "dataset_path = \"/content/drive/MyDrive/3dgs/datasets\"  # Path to datasets directory\n",
        "data_path = \"/content/drive/MyDrive/3dgs\"  # Path to where train.txt and test.txt are located\n",
        "test_txt = data_path + \"/data/test.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rcg-NpeJ_N7-"
      },
      "source": [
        "#Data Processing and Class Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXQXV7wnsIdo"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Function to save point clouds with class IDs\n",
        "def save_classified_pointcloud(points, class_ids, filename):\n",
        "    \"\"\"Save point cloud with class ID for each point.\"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"ply\\n\")\n",
        "        f.write(\"format ascii 1.0\\n\")\n",
        "        f.write(f\"element vertex {len(points)}\\n\")\n",
        "        f.write(\"property float x\\n\")\n",
        "        f.write(\"property float y\\n\")\n",
        "        f.write(\"property float z\\n\")\n",
        "        f.write(\"property int class_id\\n\")\n",
        "        f.write(\"end_header\\n\")\n",
        "\n",
        "        for i in range(len(points)):\n",
        "            x, y, z = points[i]\n",
        "            class_id = int(class_ids[i])\n",
        "            f.write(f\"{x} {y} {z} {class_id}\\n\")\n",
        "\n",
        "#Read class names from train.txt/test.txt first\n",
        "def get_classes():\n",
        "    delimiter = '/'\n",
        "    test_txt\n",
        "\n",
        "    #Read test file and extract class names\n",
        "    categories = pd.read_csv(test_txt, delimiter=delimiter, header=None, names=[\"col1\", \"col2\"])\n",
        "    categories_set = set(categories[\"col1\"])  # Get unique class names\n",
        "    sorted_classes = sorted(categories_set)  # Sort for consistency\n",
        "\n",
        "    print(f\"Sorted Categories from Dataset: {sorted_classes}\")\n",
        "    return sorted_classes\n",
        "\n",
        "#Set up class names and mappings\n",
        "CLASSES = get_classes()\n",
        "class2label = {cls: i for i, cls in enumerate(CLASSES)}\n",
        "CLASS2LABEL = class2label\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "print(f\"Class to label mapping: {CLASS2LABEL}\")\n",
        "\n",
        "sys.path.append(os.path.join(ROOT_DIR, 'models'))\n",
        "\n",
        "seg_classes = class2label\n",
        "seg_label_to_cat = {}\n",
        "for i, cat in enumerate(seg_classes.keys()):\n",
        "    seg_label_to_cat[i] = cat\n",
        "\n",
        "\n",
        "def inplace_relu(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('ReLU') != -1:\n",
        "        m.inplace = True\n",
        "\n",
        "\n",
        "#Define ExtraFeature class if not imported from elsewhere\n",
        "class ExtraFeature:\n",
        "    @staticmethod\n",
        "    def feature_by_name(name):\n",
        "        # Simple placeholder implementation\n",
        "        return name\n",
        "\n",
        "\n",
        "#Constructing the paths\n",
        "def modify_paths_train():\n",
        "    delimiter = '/'\n",
        "    train_txt = data_path + \"/data/train.txt\"\n",
        "\n",
        "    # Read train file and split into two columns\n",
        "    train_df = pd.read_csv(train_txt, delimiter=delimiter, header=None, names=[\"col1\", \"col2\"])\n",
        "\n",
        "    # Construct paths to point cloud files\n",
        "    train_df[\"combined\"] = dataset_path + \"/\" + train_df[\"col1\"] + \"/\" + train_df[\"col2\"] + \"/point_cloud/iteration_15000/point_cloud.ply\"\n",
        "\n",
        "    return (train_df[\"combined\"].tolist(), train_df[\"col1\"].tolist())\n",
        "\n",
        "def modify_paths_test():\n",
        "    delimiter = '/'\n",
        "    test_txt = data_path + \"/data/test.txt\"\n",
        "\n",
        "    #Read test file and split into two columns\n",
        "    test_df = pd.read_csv(test_txt, delimiter=delimiter, header=None, names=[\"col1\", \"col2\"])\n",
        "\n",
        "    #Construct paths to point cloud files\n",
        "    test_df[\"combined\"] = dataset_path + \"/\" + test_df[\"col1\"] + \"/\" + test_df[\"col2\"] + \"/point_cloud/iteration_15000/point_cloud.ply\"\n",
        "\n",
        "    return (test_df[\"combined\"].tolist() , test_df[\"col1\"].tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iD4oDME8OOqK"
      },
      "outputs": [],
      "source": [
        "#Define all extra feature constants BEFORE get_args()\n",
        "FEATURE_ROTATION_QUAT = 'rotation_quat'\n",
        "FEATURE_ROTATION_MATRIX = 'rotation_matrix'\n",
        "FEATURE_SCALE = 'scale'\n",
        "FEATURE_COVARIANCE = 'covariance'\n",
        "FEATURE_OPACITY = 'opacity'\n",
        "FEATURE_COLOR = 'color'\n",
        "FEATURE_REST = 'rest'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnxCP-D7CWCD"
      },
      "outputs": [],
      "source": [
        "#Sanity test making sure the labels and paths have the same lenght\n",
        "train_paths, trainlabels = modify_paths_train()\n",
        "test_paths, testlabels = modify_paths_test()\n",
        "testlabels\n",
        "\n",
        "\n",
        "if len(train_paths) == len(trainlabels) and len(test_paths) == len(testlabels):\n",
        "  print(\"both train and testing paths are the same lenght as the lables\")\n",
        "else:\n",
        "    print(\"PATHS ARE NOT SAME LENGHT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykRx--GQCrUj"
      },
      "source": [
        " ## Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBbrnu4RCC1n"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Random Sampling\n",
        "original_iter = sampler.RandomSampler.__iter__\n",
        "def patched_iter(self):\n",
        "    n = len(self.data_source)\n",
        "    if self.generator is None:\n",
        "        generator = torch.Generator()\n",
        "        generator.manual_seed(int(torch.empty((), dtype=torch.int64).random_().item()))\n",
        "    else:\n",
        "        generator = self.generator\n",
        "\n",
        "    if self.replacement:\n",
        "        for _ in range(self.num_samples // n):\n",
        "            for idx in torch.randint(0, n, size=(n,), generator=generator).tolist():\n",
        "                yield idx\n",
        "        for idx in torch.randint(0, n, size=(self.num_samples % n,), generator=generator).tolist():\n",
        "            yield idx\n",
        "    else:\n",
        "\n",
        "        for idx in torch.randperm(n, generator=generator).tolist():\n",
        "            yield idx\n",
        "\n",
        "sampler.RandomSampler.__iter__ = patched_iter\n",
        "\n",
        "# Function to save point clouds with class IDs\n",
        "def save_classified_pointcloud(points, class_ids, filename):\n",
        "    \"\"\"Save point cloud with class ID for each point.\"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"ply\\n\")\n",
        "        f.write(\"format ascii 1.0\\n\")\n",
        "        f.write(f\"element vertex {len(points)}\\n\")\n",
        "        f.write(\"property float x\\n\")\n",
        "        f.write(\"property float y\\n\")\n",
        "        f.write(\"property float z\\n\")\n",
        "        f.write(\"property int class_id\\n\")\n",
        "        f.write(\"end_header\\n\")\n",
        "\n",
        "        for i in range(len(points)):\n",
        "            x, y, z = points[i]\n",
        "            class_id = int(class_ids[i])\n",
        "            f.write(f\"{x} {y} {z} {class_id}\\n\")\n",
        "\n",
        "# Read class names from train.txt/test.txt first\n",
        "def get_classes():\n",
        "    delimiter = '/'\n",
        "    # Read test file and extract class names\n",
        "    categories = pd.read_csv(test_txt, delimiter=delimiter, header=None, names=[\"col1\", \"col2\"])\n",
        "    categories_set = set(categories[\"col1\"])  # Get unique class names\n",
        "    sorted_classes = sorted(categories_set)  # Sort for consistency\n",
        "\n",
        "    print(f\"Sorted Categories from Dataset: {sorted_classes}\")\n",
        "    return sorted_classes\n",
        "\n",
        "# Set up class names and mappings\n",
        "CLASSES = get_classes()\n",
        "class2label = {cls: i for i, cls in enumerate(CLASSES)}\n",
        "CLASS2LABEL = class2label\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "print(f\"Class to label mapping: {CLASS2LABEL}\")\n",
        "\n",
        "seg_classes = class2label\n",
        "seg_label_to_cat = {}\n",
        "for i, cat in enumerate(seg_classes.keys()):\n",
        "    seg_label_to_cat[i] = cat\n",
        "\n",
        "def inplace_relu(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('ReLU') != -1:\n",
        "        m.inplace = True\n",
        "\n",
        "# Define ExtraFeature class if not imported from elsewhere\n",
        "class ExtraFeature:\n",
        "    @staticmethod\n",
        "    def feature_by_name(name):\n",
        "        # Simple placeholder implementation\n",
        "        return name\n",
        "\n",
        "\n",
        "class TrainEnv:\n",
        "    def log_string(self, str):\n",
        "        self.logger.info(str)\n",
        "        print(str)\n",
        "\n",
        "def create_environment(args, train_paths, test_paths, train_labels, test_labels):\n",
        "    env = TrainEnv()\n",
        "\n",
        "    '''HYPER PARAMETER'''\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "\n",
        "    '''CREATE DIR'''\n",
        "    timestr = str(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M'))\n",
        "    experiment_dir = Path('./log/')\n",
        "    experiment_dir.mkdir(exist_ok=True)\n",
        "    experiment_dir = experiment_dir.joinpath('sem_seg')\n",
        "    experiment_dir.mkdir(exist_ok=True)\n",
        "    if args.log_dir is None:\n",
        "        experiment_dir = experiment_dir.joinpath(timestr)\n",
        "    else:\n",
        "        experiment_dir = experiment_dir.joinpath(args.log_dir)\n",
        "    experiment_dir.mkdir(exist_ok=True)\n",
        "    env.checkpoints_dir = experiment_dir.joinpath('checkpoints/')\n",
        "    env.checkpoints_dir.mkdir(exist_ok=True)\n",
        "    log_dir = experiment_dir.joinpath('logs/')\n",
        "    log_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    '''LOG'''\n",
        "    env.logger = logging.getLogger(\"Model\")\n",
        "    env.logger.setLevel(logging.INFO)\n",
        "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "    file_handler = logging.FileHandler('%s/%s.txt' % (log_dir, args.model))\n",
        "    file_handler.setLevel(logging.INFO)\n",
        "    file_handler.setFormatter(formatter)\n",
        "    env.logger.addHandler(file_handler)\n",
        "    env.log_string('PARAMETER ...')\n",
        "    env.log_string(args)\n",
        "\n",
        "    env.writer = SummaryWriter(log_dir=str(experiment_dir.joinpath('tensorboard')))\n",
        "\n",
        "    num_point = args.npoint\n",
        "    batch_size = args.batch_size\n",
        "\n",
        "    sampling = args.sampling\n",
        "\n",
        "    print(\"start loading training data ...\")\n",
        "    if args.dataset_type == '3DGS':\n",
        "        from datasets.composed_3dgs_dataset import Composed3DGSDataset\n",
        "\n",
        "        env.train_dataset = Composed3DGSDataset(\n",
        "            model_paths=train_paths,\n",
        "            class2label=CLASS2LABEL,  # Using class2label for label mapping\n",
        "            sampling=sampling,\n",
        "            num_point=num_point,\n",
        "            extra_features=args.extra_features  # Pass the `ExtraFeature` objects here\n",
        "        )\n",
        "    elif args.dataset_type == 'SampledMesh':\n",
        "        from datasets.composed_mesh_dataset import ComposedMeshDataset\n",
        "\n",
        "        env.train_dataset = ComposedMeshDataset(model_paths=train_paths, class2label=CLASS2LABEL, num_point=num_point)\n",
        "\n",
        "    print(\"start loading test data ...\")\n",
        "    if args.dataset_type == '3DGS':\n",
        "        env.test_dataset = Composed3DGSDataset(\n",
        "            model_paths=test_paths,\n",
        "            class2label=CLASS2LABEL,  # Using class2label for label mapping\n",
        "            sampling=sampling,\n",
        "            num_point=num_point,\n",
        "            extra_features=args.extra_features  # Pass the `ExtraFeature` objects here\n",
        "        )\n",
        "    elif args.dataset_type == 'SampledMesh':\n",
        "        env.test_dataset = ComposedMeshDataset(model_paths=test_paths, class2label=CLASS2LABEL, num_point=num_point)\n",
        "\n",
        "    def custom_worker_init_fn(worker_id):\n",
        "        # Use PyTorch's random number generator instead of NumPy's\n",
        "        worker_seed = torch.initial_seed() % 2**32\n",
        "        torch.manual_seed(worker_seed)\n",
        "        # Only set NumPy seed if it's safe to do so\n",
        "        try:\n",
        "            np.random.seed(worker_seed)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    env.trainDataLoader = torch.utils.data.DataLoader(\n",
        "        env.train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        pin_memory=False,  # Disabled pin_memory\n",
        "        drop_last=True,\n",
        "        num_workers=4,\n",
        "        worker_init_fn=custom_worker_init_fn\n",
        "    )\n",
        "\n",
        "    env.testDataLoader = torch.utils.data.DataLoader(\n",
        "        env.test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        pin_memory=False,  # Disabled pin_memory\n",
        "        drop_last=True,\n",
        "        num_workers=4,\n",
        "        worker_init_fn=custom_worker_init_fn\n",
        "    )\n",
        "\n",
        "    env.weights = torch.Tensor(env.train_dataset.label_weights).cuda()\n",
        "\n",
        "    env.log_string(\"The number of training data is: %d\" % len(env.train_dataset))\n",
        "    env.log_string(\"The number of test data is: %d\" % len(env.test_dataset))\n",
        "\n",
        "    '''MODEL LOADING'''\n",
        "    MODEL = importlib.import_module(args.model)\n",
        "\n",
        "    env.classifier = MODEL.get_model(NUM_CLASSES, env.train_dataset.get_channels_count).cuda()\n",
        "    env.classifier.apply(inplace_relu)\n",
        "    env.criterion = MODEL.get_loss().cuda()\n",
        "\n",
        "    def weights_init(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find('Conv2d') != -1:\n",
        "            torch.nn.init.xavier_normal_(m.weight.data)\n",
        "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find('Linear') != -1:\n",
        "            torch.nn.init.xavier_normal_(m.weight.data)\n",
        "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    try:\n",
        "        checkpoint = torch.load(str(experiment_dir) + '/checkpoints/model.pth')\n",
        "        env.start_epoch = checkpoint['epoch'] + 1\n",
        "        env.classifier.load_state_dict(checkpoint['model_state_dict'])\n",
        "        env.log_string('Use pretrain model')\n",
        "    except:\n",
        "        env.log_string('No existing model, starting from scratch...')\n",
        "        env.start_epoch = 0\n",
        "        env.classifier = env.classifier.apply(weights_init)\n",
        "\n",
        "    if args.optimizer == 'Adam':\n",
        "        env.optimizer = torch.optim.Adam(\n",
        "            env.classifier.parameters(),\n",
        "            lr=args.learning_rate,\n",
        "            betas=(0.9, 0.999),\n",
        "            eps=1e-08,\n",
        "            weight_decay=args.weight_decay_rate\n",
        "        )\n",
        "    else:\n",
        "        env.optimizer = torch.optim.SGD(env.classifier.parameters(), lr=args.learning_rate, momentum=0.9)\n",
        "\n",
        "    return env\n",
        "\n",
        "\n",
        "def close_environment(env):\n",
        "    env.writer.close()\n",
        "\n",
        "    handlers = env.logger.handlers[:]\n",
        "    for handler in handlers:\n",
        "        env.logger.removeHandler(handler)\n",
        "        handler.close()\n",
        "        #Show classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUOkdBJX-uHS"
      },
      "source": [
        "PointNet segmentation code I modified, with help from Claude AI\n",
        "I took the original PointNet segmentation code and made several improvements:\n",
        "- Streamlined how variables are declared for better organization\n",
        "- Added functionality to save point cloud visualization as PLY files\n",
        "- Created the EvalResults class for cleaner metric tracking\n",
        "\n",
        "Claude helped me troubleshoot the PLY file saving implementation and\n",
        "suggested refinements to the visualization approach. The core structure\n",
        "is from PointNet, but my modifications make it more usable for my needs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWerDt93EBKI"
      },
      "source": [
        "##Declare your aguments here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59Zi6VSHD9FI"
      },
      "outputs": [],
      "source": [
        "#Change your arguments here\n",
        "def get_args():\n",
        "    args = argparse.Namespace()\n",
        "\n",
        "    args.data_path = \"/content/drive/MyDrive/3dgs/datasets\" #Change to your path\n",
        "    args.model = 'pointnet2_sem_seg'\n",
        "    args.dataset_type = '3DGS'\n",
        "    args.batch_size = 8\n",
        "    args.epoch = 200\n",
        "    args.learning_rate = 0.003\n",
        "    args.gpu = '0'\n",
        "    args.optimizer = 'Adam'\n",
        "    args.log_dir = 'epochs250_learningrate_003_bs32_v0201_001_4096' #rename each time overwise the model will treat the previous version as a checkpoint\n",
        "    args.weight_decay_rate = 1e-4\n",
        "    args.npoint = 4096\n",
        "    args.lr_step_size = 5  # how often it updates\n",
        "    args.lr_decay = 0.95\n",
        "    args.eval_after_epoch = True\n",
        "    args.sampling = 'uniform'\n",
        "\n",
        "    # Test mode settings this is just to see if it will train and test (not good results)\n",
        "    args.test_mode = True #I added this so you can test a smaller sample size to see if the labeling runs and goes onto the next section\n",
        "    args.max_test_samples = 50\n",
        "    # Predefined extra features\n",
        "    predefined_extra_features = [\n",
        "        'rotation_quat',\n",
        "        'scale',\n",
        "        'opacity',\n",
        "    ]\n",
        "\n",
        "    # Convert to ExtraFeature objects\n",
        "    from data_utils.extra_feature import ExtraFeature\n",
        "    args.extra_features = [ExtraFeature.feature_by_name(feature) for feature in predefined_extra_features] if predefined_extra_features else None\n",
        "    return args\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80U2-d_FCmAI"
      },
      "source": [
        "## Training and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ8pcQlfCi1I"
      },
      "outputs": [],
      "source": [
        "def train(env, args):\n",
        "    def bn_momentum_adjust(m, momentum):\n",
        "        if isinstance(m, torch.nn.BatchNorm2d) or isinstance(m, torch.nn.BatchNorm1d):\n",
        "            m.momentum = momentum\n",
        "\n",
        "    # Set some constants for the learning scheduler\n",
        "    LEARNING_RATE_CLIP = 1e-5\n",
        "    MOMENTUM_ORIGINAL = 0.1\n",
        "    MOMENTUM_DECCAY = 0.5\n",
        "    MOMENTUM_DECCAY_STEP = args.lr_step_size\n",
        "\n",
        "    global_epoch = 0\n",
        "    best_iou = 0\n",
        "\n",
        "    #Main training loop\n",
        "    for epoch in range(env.start_epoch, args.epoch):\n",
        "        env.log_string('**** Epoch %d (%d/%s) ****' % (global_epoch + 1, epoch + 1, args.epoch))\n",
        "\n",
        "        # Decay learning rate over time\n",
        "        lr = max(args.learning_rate * (args.lr_decay ** (epoch // args.lr_step_size)), LEARNING_RATE_CLIP)\n",
        "        env.log_string('Learning rate:%f' % lr)\n",
        "        for param_group in env.optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        #Update batch norm momentum - helps stabilize training\n",
        "        momentum = MOMENTUM_ORIGINAL * (MOMENTUM_DECCAY ** (epoch // MOMENTUM_DECCAY_STEP))\n",
        "        if momentum < 0.01:\n",
        "            momentum = 0.01\n",
        "        print('BN momentum updated to: %f' % momentum)\n",
        "        env.classifier = env.classifier.apply(lambda x: bn_momentum_adjust(x, momentum))\n",
        "\n",
        "        env.writer.add_scalar('LR', lr, epoch)\n",
        "\n",
        "        # Reset metrics for this epoch\n",
        "        num_batches = len(env.trainDataLoader)\n",
        "        total_correct = 0\n",
        "        total_seen = 0\n",
        "        loss_sum = 0\n",
        "        env.classifier = env.classifier.train()\n",
        "\n",
        "        # Process each batch\n",
        "        for i, (points, target) in tqdm(enumerate(env.trainDataLoader), total=len(env.trainDataLoader), smoothing=0.9):\n",
        "            env.optimizer.zero_grad()\n",
        "\n",
        "            # Prep the point cloud data\n",
        "            points = points.data.numpy()\n",
        "            points = torch.Tensor(points)\n",
        "            points, target = points.float().cuda(), target.long().cuda()\n",
        "            points = points.transpose(2, 1)  # PointNet needs this format\n",
        "\n",
        "            # Forward pass through model\n",
        "            seg_pred, trans_feat = env.classifier(points)\n",
        "            seg_pred = seg_pred.contiguous().view(-1, NUM_CLASSES)\n",
        "\n",
        "            batch_label = target.view(-1, 1)[:, 0].cpu().data.numpy()\n",
        "            target = target.view(-1, 1)[:, 0]\n",
        "\n",
        "            # Calculate loss and update weights\n",
        "            loss = env.criterion(seg_pred, target, trans_feat, env.weights)\n",
        "            loss.backward()\n",
        "            env.optimizer.step()\n",
        "\n",
        "            # Track how we're doing\n",
        "            pred_choice = seg_pred.cpu().data.max(1)[1].numpy()\n",
        "            correct = np.sum(pred_choice == batch_label)\n",
        "            total_correct += correct\n",
        "            total_seen += (args.batch_size * args.npoint)\n",
        "            loss_sum += loss\n",
        "\n",
        "        # Log training results\n",
        "        training_loss = loss_sum / num_batches\n",
        "        training_accuracy = total_correct / float(total_seen)\n",
        "\n",
        "        env.log_string('Training mean loss: %f' % training_loss)\n",
        "        env.log_string('Training accuracy: %f' % training_accuracy)\n",
        "        env.writer.add_scalar('Train loss', training_loss, epoch)\n",
        "        env.writer.add_scalar('Train accuracy', training_accuracy, epoch)\n",
        "\n",
        "        # Save model checkpoints regularly\n",
        "        if epoch % 5 == 0 or epoch == args.epoch - 1:\n",
        "            env.log_string('Save model...')\n",
        "            savepath = str(env.checkpoints_dir) + '/model.pth'\n",
        "            env.log_string('Saving at %s' % savepath)\n",
        "            state = {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': env.classifier.state_dict(),\n",
        "                'optimizer_state_dict': env.optimizer.state_dict(),\n",
        "            }\n",
        "            torch.save(state, savepath)\n",
        "            env.log_string('Saving model....')\n",
        "\n",
        "        # Evaluation phase\n",
        "        if args.eval_after_epoch:\n",
        "            env.log_string('---- EPOCH %03d EVALUATION ----' % (global_epoch + 1))\n",
        "            eval_results = evaluate(env, args, epoch=epoch)\n",
        "\n",
        "            #Log Progress\n",
        "            env.log_string('eval point avg class IoU: %f' % eval_results.mIoU)\n",
        "            env.log_string('eval point avg class acc: %f' % (\n",
        "                eval_results.mean_class_accuracy))\n",
        "\n",
        "            # Show per-class results\n",
        "            iou_per_class_str = '------- IoU --------\\n'\n",
        "            for l in range(NUM_CLASSES):\n",
        "                iou_per_class_str += 'class %s weight: %.3f, IoU: %.3f \\n' % (\n",
        "                    seg_label_to_cat[l] + ' ' * (14 - len(seg_label_to_cat[l])),\n",
        "                    eval_results.labelweights[l - 1],\n",
        "                    eval_results.class_mIoU[l]\n",
        "                )\n",
        "\n",
        "            env.log_string(iou_per_class_str)\n",
        "            env.log_string('Eval mean loss: %f' % eval_results.loss)\n",
        "            env.log_string('Eval accuracy: %f' % eval_results.accuracy)\n",
        "\n",
        "            env.writer.add_scalar('Eval loss', eval_results.loss, epoch)\n",
        "            env.writer.add_scalar('Eval accuracy', eval_results.accuracy, epoch)\n",
        "            env.writer.add_scalar('Eval mIoU', eval_results.mIoU, epoch)\n",
        "\n",
        "            if eval_results.mIoU >= best_iou:\n",
        "                best_iou = eval_results.mIoU\n",
        "                env.log_string('Save model...')\n",
        "                savepath = str(env.checkpoints_dir) + '/best_model.pth'\n",
        "                env.log_string('Saving at %s' % savepath)\n",
        "                state = {\n",
        "                    'epoch': epoch,\n",
        "                    'class_avg_iou': eval_results.mIoU,\n",
        "                    'model_state_dict': env.classifier.state_dict(),\n",
        "                    'optimizer_state_dict': env.optimizer.state_dict(),\n",
        "                }\n",
        "                torch.save(state, savepath)\n",
        "                env.log_string('Saving model....')\n",
        "            env.log_string('Best mIoU: %f' % best_iou)\n",
        "\n",
        "        env.writer.flush()\n",
        "        global_epoch += 1\n",
        "\n",
        "\n",
        "# Container for all our evaluation metrics\n",
        "class EvalResults:\n",
        "    def __init__(self, mIoU, loss, accuracy, labelweights, mean_class_accuracy, class_mIoU):\n",
        "        self.mIoU = mIoU\n",
        "        self.loss = loss\n",
        "        self.accuracy = accuracy\n",
        "        self.labelweights = labelweights\n",
        "        self.mean_class_accuracy = mean_class_accuracy\n",
        "        self.class_mIoU = class_mIoU\n",
        "\n",
        "\n",
        "def evaluate(env, args, epoch=None):\n",
        "    with torch.no_grad():\n",
        "        # Setup tracking variables\n",
        "        num_batches = len(env.testDataLoader)\n",
        "        total_correct = 0\n",
        "        total_seen = 0\n",
        "        loss_sum = 0\n",
        "        labelweights = np.zeros(NUM_CLASSES)\n",
        "        total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
        "        total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
        "        total_iou_deno_class = [0 for _ in range(NUM_CLASSES)]\n",
        "        env.classifier = env.classifier.eval()  # Switch to eval mode\n",
        "\n",
        "        # Save visualization files every 50 epochs\n",
        "        save_visualization = (epoch is not None) and (epoch % 50 == 0 or epoch == args.epoch - 1)\n",
        "\n",
        "        # Need these lists for visualization\n",
        "        if save_visualization:\n",
        "            all_points = []\n",
        "            all_predictions = []\n",
        "            all_ground_truth = []\n",
        "\n",
        "        # Process test batches\n",
        "        for i, (points, target) in tqdm(enumerate(env.testDataLoader), total=len(env.testDataLoader), smoothing=0.9):\n",
        "            original_points = points.data.numpy()\n",
        "\n",
        "            points = torch.Tensor(original_points)\n",
        "            points, target = points.float().cuda(), target.long().cuda()\n",
        "            points = points.transpose(2, 1)\n",
        "\n",
        "            # Get model predictions\n",
        "            seg_pred, trans_feat = env.classifier(points)\n",
        "            pred_val = seg_pred.contiguous().cpu().data.numpy()\n",
        "            seg_pred = seg_pred.contiguous().view(-1, NUM_CLASSES)\n",
        "\n",
        "            batch_label = target.cpu().data.numpy()\n",
        "            target = target.view(-1, 1)[:, 0]\n",
        "            loss = env.criterion(seg_pred, target, trans_feat, env.weights)\n",
        "            loss_sum += loss\n",
        "            pred_val = np.argmax(pred_val, 2)  # Get class predictions\n",
        "            correct = np.sum((pred_val == batch_label))\n",
        "            total_correct += correct\n",
        "            total_seen += (args.batch_size * args.npoint)\n",
        "            tmp, _ = np.histogram(batch_label, range(NUM_CLASSES + 1))\n",
        "            labelweights += tmp\n",
        "\n",
        "            # Per-class metrics\n",
        "            for l in range(NUM_CLASSES):\n",
        "                total_seen_class[l] += np.sum((batch_label == l))\n",
        "                total_correct_class[l] += np.sum((pred_val == l) & (batch_label == l))\n",
        "                total_iou_deno_class[l] += np.sum(((pred_val == l) | (batch_label == l)))\n",
        "\n",
        "            # Collect visualization data if needed\n",
        "            if save_visualization:\n",
        "                for b in range(original_points.shape[0]):\n",
        "                    # Just grab XYZ coordinates\n",
        "                    batch_points = original_points[b, :, :3]\n",
        "                    batch_pred = pred_val[b]\n",
        "                    batch_gt = batch_label[b]\n",
        "\n",
        "                    all_points.append(batch_points)\n",
        "                    all_predictions.append(batch_pred)\n",
        "                    all_ground_truth.append(batch_gt)\n",
        "\n",
        "        # Save colorized point clouds for visualization\n",
        "        if save_visualization:\n",
        "            vis_dir = os.path.join(str(env.checkpoints_dir), 'visualizations')\n",
        "            os.makedirs(vis_dir, exist_ok=True)\n",
        "\n",
        "            # Combine all the collected data\n",
        "            full_points = np.vstack(all_points)\n",
        "            full_predictions = np.concatenate(all_predictions)\n",
        "            full_ground_truth = np.concatenate(all_ground_truth)\n",
        "\n",
        "            # Save as PLY files that can be viewed in 3D software\n",
        "            pred_filename = os.path.join(vis_dir, f'epoch_{epoch}_full_prediction.ply')\n",
        "            save_classified_pointcloud(full_points, full_predictions, pred_filename)\n",
        "\n",
        "            gt_filename = os.path.join(vis_dir, f'epoch_{epoch}_full_groundtruth.ply')\n",
        "            save_classified_pointcloud(full_points, full_ground_truth, gt_filename)\n",
        "\n",
        "        # Calculate final metrics\n",
        "        labelweights = labelweights.astype(np.float32) / np.sum(labelweights.astype(np.float32))\n",
        "        mIoU = np.mean(np.array(total_correct_class) / (np.array(total_iou_deno_class, dtype=float) + 1e-6))\n",
        "        eval_loss = loss_sum / float(num_batches)\n",
        "        eval_accuracy = total_correct / float(total_seen)\n",
        "        mean_class_accuracy = np.mean(np.array(total_correct_class) / (np.array(total_seen_class, dtype=float) + 1e-6))\n",
        "        class_mIoU = [total_correct_class[l] / float(total_iou_deno_class[l]) for l in range(NUM_CLASSES)]\n",
        "\n",
        "        return EvalResults(mIoU, eval_loss, eval_accuracy, labelweights, mean_class_accuracy, class_mIoU)\n",
        "\n",
        "def main():\n",
        "    # Get the config settings\n",
        "    args = get_args()\n",
        "\n",
        "    # Load dataset paths and their labels\n",
        "    train_paths, trainlabels = modify_paths_train()\n",
        "    test_paths, testlabels = modify_paths_test()\n",
        "\n",
        "    # Use fewer samples in test mode\n",
        "    if args.test_mode:\n",
        "        print(f\"Test mode enabled - using only {args.max_test_samples} samples\")\n",
        "        train_paths = train_paths[:args.max_test_samples]\n",
        "        trainlabels = trainlabels[:args.max_test_samples]\n",
        "        test_paths = test_paths[:args.max_test_samples]\n",
        "        testlabels = testlabels[:args.max_test_samples]\n",
        "\n",
        "    # Make sure our data is valid\n",
        "    if len(train_paths) == len(trainlabels) and len(test_paths) == len(testlabels):\n",
        "        # Setup and run training\n",
        "        env = create_environment(args, train_paths, test_paths, trainlabels, testlabels)\n",
        "        train(env, args)\n",
        "        close_environment(env)\n",
        "    else:\n",
        "        # Something's wrong with the data\n",
        "        raise Exception(\"The list of labels for the train and test data do not match lengths.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}