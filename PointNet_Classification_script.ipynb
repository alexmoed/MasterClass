{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexmoed/MasterClass/blob/3D-Pointnet%2B%2B/PointNet_Classification_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnOKJBB5xk79"
      },
      "outputs": [],
      "source": [
        " # !git clone https://github.com/karol-202/direct-3dgs-segmentation \"/content/drive/MyDrive/3dgs/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8Ax15U0J8pB",
        "outputId": "064e2f9e-d36a-44b3-c649-dec1383b4638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "#change the directory to the correct spot on google drive\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @brief Train a semantic segmentation model for 3D Gaussian Splats\n",
        "# Modified from :-\n",
        "# Yanx27 (2019). PointNet_Pointnet2_pytorch [online].\n",
        "# [Accessed 2024]. Available from: \"https://github.com/yanx27/Pointnet_Pointnet2_pytorch\"\n",
        "# Based on research from:\n",
        "# Jurski, K. (2024). Semantic 3D segmentation of 3D Gaussian Splats: Assessing existing\n",
        "# point cloud segmentation techniques on semantic segmentation of synthetic 3D Gaussian\n",
        "# Splats scenes. Bachelor's Thesis, Delft University of Technology.\n",
        "# Extended implementation: \"https://github.com/karol-202/direct-3dgs-segmentation\""
      ],
      "metadata": {
        "id": "c-tX7hdrPIEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PointNet ++ for Gaussian splats"
      ],
      "metadata": {
        "id": "w7gebjNX7XYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing depencencies"
      ],
      "metadata": {
        "id": "EJCG4e5x7cQe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciTW75Hh_6_w",
        "outputId": "5aca18de-8369-464a-8152-df522a3f056e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plyfile\n",
            "  Downloading plyfile-1.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from plyfile) (2.0.2)\n",
            "Downloading plyfile-1.1-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: plyfile\n",
            "Successfully installed plyfile-1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install plyfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlodEOZnyQWS",
        "outputId": "f5cb94b0-4d2e-4589-836e-9afce8a6ab55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "\u001b[33mWARNING: Skipping pytorch3d as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#Uninstall any versions of pytorch3d\n",
        "!pip uninstall -y torch torchvision torchaudio pytorch3d\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egDDaEHnyT9X",
        "outputId": "c62aa2ba-b42e-4c9e-eb2e-e7ac3a3cc0ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/nightly/cu121\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/torch-2.6.0.dev20241112%2Bcu121-cp311-cp311-linux_x86_64.whl (768.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.0/768.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/torchvision-0.20.0.dev20241112%2Bcu121-cp311-cp311-linux_x86_64.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m734.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/torchaudio-2.5.0.dev20241112%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m319.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-triton==3.1.0+cf34004b8a (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/pytorch_triton-3.1.0%2Bcf34004b8a-cp311-cp311-linux_x86_64.whl (239.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.7/239.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: pytorch-triton, nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 pytorch-triton-3.1.0+cf34004b8a torch-2.6.0.dev20241112+cu121 torchaudio-2.5.0.dev20241112+cu121 torchvision-0.20.0.dev20241112+cu121\n"
          ]
        }
      ],
      "source": [
        "#Run this exact version of torch vision others dont seem to work with pytorch 3d\n",
        "!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dSilur4IzHSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fdf2a42-120b-45b3-f12c-7aac403d6263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (3.31.6)\n",
            "Collecting cmake\n",
            "  Downloading cmake-4.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Downloading cmake-4.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja, cmake\n",
            "  Attempting uninstall: cmake\n",
            "    Found existing installation: cmake 3.31.6\n",
            "    Uninstalling cmake-3.31.6:\n",
            "      Successfully uninstalled cmake-3.31.6\n",
            "Successfully installed cmake-4.0.0 ninja-1.11.1.4\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.0.2)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.2.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath) (4.13.2)\n",
            "Collecting portalocker (from iopath)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=4de1305035d338d95e3262b561d152372db85b807f59ed1a8d1a9e5e12b79484\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=52c2397db56c46cfad069b6a6cd90ef38522d7fcb5717119df232b196197c3dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.1.1 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install -U cmake ninja\n",
        "!pip install fvcore iopath\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WNViPp8JzCT5",
        "outputId": "f459ee26-5106-4d84-c81a-369a53aa1bec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/pytorch3d.git@stable\n",
            "  Cloning https://github.com/facebookresearch/pytorch3d.git (to revision stable) to /tmp/pip-req-build-2jn6c_uu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorch3d.git /tmp/pip-req-build-2jn6c_uu\n",
            "  Running command git checkout -q 75ebeeaea0908c5527e7b1e305fbc7681382db47\n",
            "  Resolved https://github.com/facebookresearch/pytorch3d.git to commit 75ebeeaea0908c5527e7b1e305fbc7681382db47\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.11/dist-packages (from pytorch3d==0.7.8) (0.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from iopath->pytorch3d==0.7.8) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath->pytorch3d==0.7.8) (4.13.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath->pytorch3d==0.7.8) (3.1.1)\n",
            "Building wheels for collected packages: pytorch3d\n",
            "  Building wheel for pytorch3d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch3d: filename=pytorch3d-0.7.8-cp311-cp311-linux_x86_64.whl size=60074601 sha256=e6471c8884e7e9e789f2ec75c7f25bfe96595501b2e6694eb7c68b8dc7ea730b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f0wfc8x2/wheels/08/90/1b/df18c3e3634f86278e793b87f37ea4c58d0c36731196122518\n",
            "Successfully built pytorch3d\n",
            "Installing collected packages: pytorch3d\n",
            "Successfully installed pytorch3d-0.7.8\n"
          ]
        }
      ],
      "source": [
        "#Install the newest stable version of pytorch3d It takes awhile this is normal\n",
        "!pip install \"git+https://github.com/facebookresearch/pytorch3d.git@stable\"\n",
        "#It will get stuck on building wheels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDUU4_c1xtCO",
        "outputId": "c1c696d0-6812-4c5b-f6ef-6aa4d9cd0d1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7.8\n"
          ]
        }
      ],
      "source": [
        "import pytorch3d\n",
        "print(pytorch3d.__version__)\n",
        "#make sure its the following version\n",
        "#0.7.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eZX2ATSaRn5-",
        "outputId": "de848627-93ee-46d2-c581-1ac5dbb47de3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trimesh\n",
            "  Downloading trimesh-4.6.8-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from trimesh) (2.0.2)\n",
            "Downloading trimesh-4.6.8-py3-none-any.whl (709 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/709.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.3/709.3 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trimesh\n",
            "Successfully installed trimesh-4.6.8\n"
          ]
        }
      ],
      "source": [
        "!pip install trimesh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "VBmJqHSvu1p5",
        "outputId": "4a854162-ec73-4730-a406-4c500a29de22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0.dev20241112+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uTYwJLMKRA0k",
        "outputId": "1a8a66f6-a519-495f-f4d4-583f5008f86a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/3dgs/ #Change to your repo'\n",
            "/content/drive/MyDrive/3dgs\n"
          ]
        }
      ],
      "source": [
        "# Partially from: https://github.com/yanx27/Pointnet_Pointnet2_pytorch\n",
        "import argparse\n",
        "import os\n",
        "import datetime\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import importlib\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Add this patch to fix NumPy issue with PyTorch DataLoader\n",
        "import torch.utils.data.sampler as sampler\n",
        "# Add this patch to fix NumPy issue with PyTorch DataLoader\n",
        "import torch.utils.data.sampler as sampler\n",
        "\n",
        "%cd /content/drive/MyDrive/3dgs/ #Change to your repo\n",
        "\n",
        "# Custom imports\n",
        "from data_utils.extra_feature import ExtraFeature\n",
        "from datasets.base_3dgs_dataset import Base3DGSDataset\n",
        "from datasets.composed_mesh_dataset import ComposedMeshDataset\n",
        "from datasets.composed_3dgs_dataset import Composed3DGSDataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define paths\n"
      ],
      "metadata": {
        "id": "qs6iXDvz_R3l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RngAxBqksrqB"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "BASE_DIR = \"/content/drive/MyDrive/3dgs\"  # Path for Google Colab\n",
        "experiment_dir = BASE_DIR\n",
        "ROOT_DIR = BASE_DIR\n",
        "dataset_path = \"/content/drive/MyDrive/3dgs/datasets\"  # Path to datasets directory\n",
        "data_path = \"/content/drive/MyDrive/3dgs\"  # Path to where train.txt and test.txt are located\n",
        "test_txt = data_path + \"/data/test.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Processing and Class Configuration"
      ],
      "metadata": {
        "id": "Rcg-NpeJ_N7-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xXQXV7wnsIdo",
        "outputId": "d7738af5-ff0d-4b8a-c9ba-48b1ee9863ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted Categories from Dataset: ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
            "Class to label mapping: {'bathtub': 0, 'bed': 1, 'chair': 2, 'desk': 3, 'dresser': 4, 'monitor': 5, 'night_stand': 6, 'sofa': 7, 'table': 8, 'toilet': 9}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Function to save point clouds with class IDs\n",
        "def save_classified_pointcloud(points, class_ids, filename):\n",
        "    \"\"\"Save point cloud with class ID for each point.\"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"ply\\n\")\n",
        "        f.write(\"format ascii 1.0\\n\")\n",
        "        f.write(f\"element vertex {len(points)}\\n\")\n",
        "        f.write(\"property float x\\n\")\n",
        "        f.write(\"property float y\\n\")\n",
        "        f.write(\"property float z\\n\")\n",
        "        f.write(\"property int class_id\\n\")\n",
        "        f.write(\"end_header\\n\")\n",
        "\n",
        "        for i in range(len(points)):\n",
        "            x, y, z = points[i]\n",
        "            class_id = int(class_ids[i])\n",
        "            f.write(f\"{x} {y} {z} {class_id}\\n\")\n",
        "\n",
        "#Read class names from train.txt/test.txt first\n",
        "def get_classes():\n",
        "    delimiter = '/'\n",
        "    test_txt\n",
        "\n",
        "    #Read test file and extract class names\n",
        "    categories = pd.read_csv(test_txt, delimiter=delimiter, header=None, names=[\"col1\", \"col2\"])\n",
        "    categories_set = set(categories[\"col1\"])  # Get unique class names\n",
        "    sorted_classes = sorted(categories_set)  # Sort for consistency\n",
        "\n",
        "    print(f\"Sorted Categories from Dataset: {sorted_classes}\")\n",
        "    return sorted_classes\n",
        "\n",
        "#Set up class names and mappings\n",
        "CLASSES = get_classes()\n",
        "class2label = {cls: i for i, cls in enumerate(CLASSES)}\n",
        "CLASS2LABEL = class2label\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "print(f\"Class to label mapping: {CLASS2LABEL}\")\n",
        "\n",
        "sys.path.append(os.path.join(ROOT_DIR, 'models'))\n",
        "\n",
        "seg_classes = class2label\n",
        "seg_label_to_cat = {}\n",
        "for i, cat in enumerate(seg_classes.keys()):\n",
        "    seg_label_to_cat[i] = cat\n",
        "\n",
        "\n",
        "def inplace_relu(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('ReLU') != -1:\n",
        "        m.inplace = True\n",
        "\n",
        "\n",
        "#Define ExtraFeature class if not imported from elsewhere\n",
        "class ExtraFeature:\n",
        "    @staticmethod\n",
        "    def feature_by_name(name):\n",
        "        # Simple placeholder implementation\n",
        "        return name\n",
        "\n",
        "\n",
        "#Constructing the paths\n",
        "def modify_paths_train():\n",
        "    delimiter = '/'\n",
        "    train_txt = data_path + \"/data/train.txt\"\n",
        "\n",
        "    # Read train file and split into two columns\n",
        "    train_df = pd.read_csv(train_txt, delimiter=delimiter, header=None, names=[\"col1\", \"col2\"])\n",
        "\n",
        "    # Construct paths to point cloud files\n",
        "    train_df[\"combined\"] = dataset_path + \"/\" + train_df[\"col1\"] + \"/\" + train_df[\"col2\"] + \"/point_cloud/iteration_15000/point_cloud.ply\"\n",
        "\n",
        "    return (train_df[\"combined\"].tolist(), train_df[\"col1\"].tolist())\n",
        "\n",
        "def modify_paths_test():\n",
        "    delimiter = '/'\n",
        "    test_txt = data_path + \"/data/test.txt\"\n",
        "\n",
        "    #Read test file and split into two columns\n",
        "    test_df = pd.read_csv(test_txt, delimiter=delimiter, header=None, names=[\"col1\", \"col2\"])\n",
        "\n",
        "    #Construct paths to point cloud files\n",
        "    test_df[\"combined\"] = dataset_path + \"/\" + test_df[\"col1\"] + \"/\" + test_df[\"col2\"] + \"/point_cloud/iteration_15000/point_cloud.ply\"\n",
        "\n",
        "    return (test_df[\"combined\"].tolist() , test_df[\"col1\"].tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iD4oDME8OOqK"
      },
      "outputs": [],
      "source": [
        "#Define all extra feature constants BEFORE get_args()\n",
        "FEATURE_ROTATION_QUAT = 'rotation_quat'\n",
        "FEATURE_ROTATION_MATRIX = 'rotation_matrix'\n",
        "FEATURE_SCALE = 'scale'\n",
        "FEATURE_COVARIANCE = 'covariance'\n",
        "FEATURE_OPACITY = 'opacity'\n",
        "FEATURE_COLOR = 'color'\n",
        "FEATURE_REST = 'rest'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gnxCP-D7CWCD",
        "outputId": "0dbd2594-b865-49e4-b98d-f249ae43e99b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "both train and testing paths are the same lenght as the lables\n"
          ]
        }
      ],
      "source": [
        "#Sanity test making sure the labels and paths have the same lenght meaning theres a l\n",
        "train_paths, trainlabels = modify_paths_train()\n",
        "test_paths, testlabels = modify_paths_test()\n",
        "testlabels\n",
        "\n",
        "\n",
        "if len(train_paths) == len(trainlabels) and len(test_paths) == len(testlabels):\n",
        "  print(\"both train and testing paths are the same lenght as the lables\")\n",
        "else:\n",
        "    print(\"PATHS ARE NOT SAME LENGHT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Setup and Configuration"
      ],
      "metadata": {
        "id": "ykRx--GQCrUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Partially from: https://github.com/yanx27/Pointnet_Pointnet2_pytorch\n",
        "\n",
        "\n",
        "# Add this patch to fix NumPy issue with PyTorch DataLoader\n",
        "import torch.utils.data.sampler as sampler\n",
        "\n",
        "# Random Sampling\n",
        "original_iter = sampler.RandomSampler.__iter__\n",
        "def patched_iter(self):\n",
        "    n = len(self.data_source)\n",
        "    if self.generator is None:\n",
        "        generator = torch.Generator()\n",
        "        generator.manual_seed(int(torch.empty((), dtype=torch.int64).random_().item()))\n",
        "    else:\n",
        "        generator = self.generator\n",
        "\n",
        "    if self.replacement:\n",
        "        for _ in range(self.num_samples // n):\n",
        "            for idx in torch.randint(0, n, size=(n,), generator=generator).tolist():\n",
        "                yield idx\n",
        "        for idx in torch.randint(0, n, size=(self.num_samples % n,), generator=generator).tolist():\n",
        "            yield idx\n",
        "    else:\n",
        "\n",
        "        for idx in torch.randperm(n, generator=generator).tolist():\n",
        "            yield idx\n",
        "\n",
        "# Apply the patch\n",
        "sampler.RandomSampler.__iter__ = patched_iter\n",
        "\n",
        "# Function to save point clouds with class IDs\n",
        "def save_classified_pointcloud(points, class_ids, filename):\n",
        "    \"\"\"Save point cloud with class ID for each point.\"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"ply\\n\")\n",
        "        f.write(\"format ascii 1.0\\n\")\n",
        "        f.write(f\"element vertex {len(points)}\\n\")\n",
        "        f.write(\"property float x\\n\")\n",
        "        f.write(\"property float y\\n\")\n",
        "        f.write(\"property float z\\n\")\n",
        "        f.write(\"property int class_id\\n\")\n",
        "        f.write(\"end_header\\n\")\n",
        "\n",
        "        for i in range(len(points)):\n",
        "            x, y, z = points[i]\n",
        "            class_id = int(class_ids[i])\n",
        "            f.write(f\"{x} {y} {z} {class_id}\\n\")\n",
        "\n",
        "# Read class names from train.txt/test.txt first\n",
        "def get_classes():\n",
        "    delimiter = '/'\n",
        "    # Read test file and extract class names\n",
        "    categories = pd.read_csv(test_txt, delimiter=delimiter, header=None, names=[\"col1\", \"col2\"])\n",
        "    categories_set = set(categories[\"col1\"])  # Get unique class names\n",
        "    sorted_classes = sorted(categories_set)  # Sort for consistency\n",
        "\n",
        "    print(f\"Sorted Categories from Dataset: {sorted_classes}\")\n",
        "    return sorted_classes\n",
        "\n",
        "# Set up class names and mappings\n",
        "CLASSES = get_classes()\n",
        "class2label = {cls: i for i, cls in enumerate(CLASSES)}\n",
        "CLASS2LABEL = class2label\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "print(f\"Class to label mapping: {CLASS2LABEL}\")\n",
        "\n",
        "seg_classes = class2label\n",
        "seg_label_to_cat = {}\n",
        "for i, cat in enumerate(seg_classes.keys()):\n",
        "    seg_label_to_cat[i] = cat\n",
        "\n",
        "def inplace_relu(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('ReLU') != -1:\n",
        "        m.inplace = True\n",
        "\n",
        "# Define ExtraFeature class if not imported from elsewhere\n",
        "class ExtraFeature:\n",
        "    @staticmethod\n",
        "    def feature_by_name(name):\n",
        "        # Simple placeholder implementation\n",
        "        return name\n",
        "\n",
        "# Constructing the paths\n",
        "def modify_paths_train():\n",
        "    delimiter = '/'\n",
        "    train_txt = data_path + \"/data/train.txt\"\n",
        "\n",
        "    # Read train file and split into two columns\n",
        "    train_df = pd.read_csv(train_txt, delimiter=delimiter, header=None, names=[\"col1\", \"col2\"])\n",
        "\n",
        "    # Construct paths to point cloud files\n",
        "    train_df[\"combined\"] = dataset_path + \"/\" + train_df[\"col1\"] + \"/\" + train_df[\"col2\"] + \"/point_cloud/iteration_15000/point_cloud.ply\"\n",
        "\n",
        "    return (train_df[\"combined\"].tolist(), train_df[\"col1\"].tolist())\n",
        "\n",
        "def modify_paths_test():\n",
        "    delimiter = '/'\n",
        "    test_txt = data_path + \"/data/test.txt\"\n",
        "\n",
        "    # Read test file and split into two columns\n",
        "    test_df = pd.read_csv(test_txt, delimiter=delimiter, header=None, names=[\"col1\", \"col2\"])\n",
        "\n",
        "    # Construct paths to point cloud files\n",
        "    test_df[\"combined\"] = dataset_path + \"/\" + test_df[\"col1\"] + \"/\" + test_df[\"col2\"] + \"/point_cloud/iteration_15000/point_cloud.ply\"\n",
        "\n",
        "    return (test_df[\"combined\"].tolist(), test_df[\"col1\"].tolist())\n",
        "\n",
        "class TrainEnv:\n",
        "    def log_string(self, str):\n",
        "        self.logger.info(str)\n",
        "        print(str)\n",
        "\n",
        "def create_environment(args, train_paths, test_paths, train_labels, test_labels):\n",
        "    env = TrainEnv()\n",
        "\n",
        "    '''HYPER PARAMETER'''\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "\n",
        "    '''CREATE DIR'''\n",
        "    timestr = str(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M'))\n",
        "    experiment_dir = Path('./log/')\n",
        "    experiment_dir.mkdir(exist_ok=True)\n",
        "    experiment_dir = experiment_dir.joinpath('sem_seg')\n",
        "    experiment_dir.mkdir(exist_ok=True)\n",
        "    if args.log_dir is None:\n",
        "        experiment_dir = experiment_dir.joinpath(timestr)\n",
        "    else:\n",
        "        experiment_dir = experiment_dir.joinpath(args.log_dir)\n",
        "    experiment_dir.mkdir(exist_ok=True)\n",
        "    env.checkpoints_dir = experiment_dir.joinpath('checkpoints/')\n",
        "    env.checkpoints_dir.mkdir(exist_ok=True)\n",
        "    log_dir = experiment_dir.joinpath('logs/')\n",
        "    log_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    '''LOG'''\n",
        "    env.logger = logging.getLogger(\"Model\")\n",
        "    env.logger.setLevel(logging.INFO)\n",
        "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "    file_handler = logging.FileHandler('%s/%s.txt' % (log_dir, args.model))\n",
        "    file_handler.setLevel(logging.INFO)\n",
        "    file_handler.setFormatter(formatter)\n",
        "    env.logger.addHandler(file_handler)\n",
        "    env.log_string('PARAMETER ...')\n",
        "    env.log_string(args)\n",
        "\n",
        "    env.writer = SummaryWriter(log_dir=str(experiment_dir.joinpath('tensorboard')))\n",
        "\n",
        "    num_point = args.npoint\n",
        "    batch_size = args.batch_size\n",
        "\n",
        "    sampling = args.sampling\n",
        "\n",
        "    print(\"start loading training data ...\")\n",
        "    if args.dataset_type == '3DGS':\n",
        "        from datasets.composed_3dgs_dataset import Composed3DGSDataset\n",
        "\n",
        "        env.train_dataset = Composed3DGSDataset(\n",
        "            model_paths=train_paths,\n",
        "            class2label=CLASS2LABEL,  # Using class2label for label mapping\n",
        "            sampling=sampling,\n",
        "            num_point=num_point,\n",
        "            extra_features=args.extra_features  # Pass the `ExtraFeature` objects here\n",
        "        )\n",
        "    elif args.dataset_type == 'SampledMesh':\n",
        "        from datasets.composed_mesh_dataset import ComposedMeshDataset\n",
        "\n",
        "        env.train_dataset = ComposedMeshDataset(model_paths=train_paths, class2label=CLASS2LABEL, num_point=num_point)\n",
        "\n",
        "    print(\"start loading test data ...\")\n",
        "    if args.dataset_type == '3DGS':\n",
        "        env.test_dataset = Composed3DGSDataset(\n",
        "            model_paths=test_paths,\n",
        "            class2label=CLASS2LABEL,  # Using class2label for label mapping\n",
        "            sampling=sampling,\n",
        "            num_point=num_point,\n",
        "            extra_features=args.extra_features  # Pass the `ExtraFeature` objects here\n",
        "        )\n",
        "    elif args.dataset_type == 'SampledMesh':\n",
        "        env.test_dataset = ComposedMeshDataset(model_paths=test_paths, class2label=CLASS2LABEL, num_point=num_point)\n",
        "\n",
        "    # Modified DataLoader configuration to avoid NumPy issue\n",
        "    def custom_worker_init_fn(worker_id):\n",
        "        # Use PyTorch's random number generator instead of NumPy's\n",
        "        worker_seed = torch.initial_seed() % 2**32\n",
        "        torch.manual_seed(worker_seed)\n",
        "        # Only set NumPy seed if it's safe to do so\n",
        "        try:\n",
        "            np.random.seed(worker_seed)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    env.trainDataLoader = torch.utils.data.DataLoader(\n",
        "        env.train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        pin_memory=False,  # Disabled pin_memory\n",
        "        drop_last=True,\n",
        "        num_workers=4,\n",
        "        worker_init_fn=custom_worker_init_fn\n",
        "    )\n",
        "\n",
        "    env.testDataLoader = torch.utils.data.DataLoader(\n",
        "        env.test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        pin_memory=False,  # Disabled pin_memory\n",
        "        drop_last=True,\n",
        "        num_workers=4,\n",
        "        worker_init_fn=custom_worker_init_fn\n",
        "    )\n",
        "\n",
        "    env.weights = torch.Tensor(env.train_dataset.label_weights).cuda()\n",
        "\n",
        "    env.log_string(\"The number of training data is: %d\" % len(env.train_dataset))\n",
        "    env.log_string(\"The number of test data is: %d\" % len(env.test_dataset))\n",
        "\n",
        "    '''MODEL LOADING'''\n",
        "    MODEL = importlib.import_module(args.model)\n",
        "\n",
        "    env.classifier = MODEL.get_model(NUM_CLASSES, env.train_dataset.get_channels_count).cuda()\n",
        "    env.classifier.apply(inplace_relu)\n",
        "    env.criterion = MODEL.get_loss().cuda()\n",
        "\n",
        "    def weights_init(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find('Conv2d') != -1:\n",
        "            torch.nn.init.xavier_normal_(m.weight.data)\n",
        "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find('Linear') != -1:\n",
        "            torch.nn.init.xavier_normal_(m.weight.data)\n",
        "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    try:\n",
        "        checkpoint = torch.load(str(experiment_dir) + '/checkpoints/model.pth')\n",
        "        env.start_epoch = checkpoint['epoch'] + 1\n",
        "        env.classifier.load_state_dict(checkpoint['model_state_dict'])\n",
        "        env.log_string('Use pretrain model')\n",
        "    except:\n",
        "        env.log_string('No existing model, starting from scratch...')\n",
        "        env.start_epoch = 0\n",
        "        env.classifier = env.classifier.apply(weights_init)\n",
        "\n",
        "    if args.optimizer == 'Adam':\n",
        "        env.optimizer = torch.optim.Adam(\n",
        "            env.classifier.parameters(),\n",
        "            lr=args.learning_rate,\n",
        "            betas=(0.9, 0.999),\n",
        "            eps=1e-08,\n",
        "            weight_decay=args.weight_decay_rate\n",
        "        )\n",
        "    else:\n",
        "        env.optimizer = torch.optim.SGD(env.classifier.parameters(), lr=args.learning_rate, momentum=0.9)\n",
        "\n",
        "    return env\n",
        "\n",
        "\n",
        "def close_environment(env):\n",
        "    env.writer.close()\n",
        "\n",
        "    handlers = env.logger.handlers[:]\n",
        "    for handler in handlers:\n",
        "        env.logger.removeHandler(handler)\n",
        "        handler.close()\n",
        "        #Show classes"
      ],
      "metadata": {
        "id": "EBbrnu4RCC1n",
        "outputId": "531af5da-9fd3-4519-d5f8-11f979a647f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted Categories from Dataset: ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
            "Class to label mapping: {'bathtub': 0, 'bed': 1, 'chair': 2, 'desk': 3, 'dresser': 4, 'monitor': 5, 'night_stand': 6, 'sofa': 7, 'table': 8, 'toilet': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Declare your aguments here"
      ],
      "metadata": {
        "id": "uWerDt93EBKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Change your arguments here\n",
        "def get_args():\n",
        "    args = argparse.Namespace()\n",
        "\n",
        "    args.data_path = \"/content/drive/MyDrive/3dgs/datasets\" #Change to your path\n",
        "    args.model = 'pointnet2_sem_seg'\n",
        "    args.dataset_type = '3DGS'\n",
        "    args.batch_size = 8\n",
        "    args.epoch = 200\n",
        "    args.learning_rate = 0.003\n",
        "    args.gpu = '0'\n",
        "    args.optimizer = 'Adam'\n",
        "    args.log_dir = 'epochs250_learningrate_003_bs32_v027_001_4096' #rename each time overwise the model will treat the previous version as a checkpoint\n",
        "    args.weight_decay_rate = 1e-4\n",
        "    args.npoint = 4096\n",
        "    args.lr_step_size = 5  # how often it updates\n",
        "    args.lr_decay = 0.95\n",
        "    args.eval_after_epoch = True\n",
        "    args.sampling = 'uniform'\n",
        "\n",
        "    # Test mode settings this is just to see if it will train and test (not good results)\n",
        "    args.test_mode = True #I added this so you can test a smaller sample size to see if the labeling runs and goes onto the next section\n",
        "    args.max_test_samples = 200\n",
        "    # Predefined extra features\n",
        "    predefined_extra_features = [\n",
        "        'rotation_quat',\n",
        "        'scale',\n",
        "        'opacity',\n",
        "    ]\n",
        "\n",
        "    # Convert to ExtraFeature objects\n",
        "    from data_utils.extra_feature import ExtraFeature\n",
        "    args.extra_features = [ExtraFeature.feature_by_name(feature) for feature in predefined_extra_features] if predefined_extra_features else None\n",
        "    return args\n"
      ],
      "metadata": {
        "id": "59Zi6VSHD9FI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation\n"
      ],
      "metadata": {
        "id": "80U2-d_FCmAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(env, args):\n",
        "    def bn_momentum_adjust(m, momentum):\n",
        "        if isinstance(m, torch.nn.BatchNorm2d) or isinstance(m, torch.nn.BatchNorm1d):\n",
        "            m.momentum = momentum\n",
        "\n",
        "    # Set some constants for the learning scheduler\n",
        "    LEARNING_RATE_CLIP = 1e-5\n",
        "    MOMENTUM_ORIGINAL = 0.1\n",
        "    MOMENTUM_DECCAY = 0.5\n",
        "    MOMENTUM_DECCAY_STEP = args.lr_step_size\n",
        "\n",
        "    global_epoch = 0\n",
        "    best_iou = 0\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(env.start_epoch, args.epoch):\n",
        "        env.log_string('**** Epoch %d (%d/%s) ****' % (global_epoch + 1, epoch + 1, args.epoch))\n",
        "\n",
        "        # Decay learning rate over time\n",
        "        lr = max(args.learning_rate * (args.lr_decay ** (epoch // args.lr_step_size)), LEARNING_RATE_CLIP)\n",
        "        env.log_string('Learning rate:%f' % lr)\n",
        "        for param_group in env.optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        # Update batch norm momentum - helps stabilize training\n",
        "        momentum = MOMENTUM_ORIGINAL * (MOMENTUM_DECCAY ** (epoch // MOMENTUM_DECCAY_STEP))\n",
        "        if momentum < 0.01:\n",
        "            momentum = 0.01\n",
        "        print('BN momentum updated to: %f' % momentum)\n",
        "        env.classifier = env.classifier.apply(lambda x: bn_momentum_adjust(x, momentum))\n",
        "\n",
        "        env.writer.add_scalar('LR', lr, epoch)\n",
        "\n",
        "        # Reset metrics for this epoch\n",
        "        num_batches = len(env.trainDataLoader)\n",
        "        total_correct = 0\n",
        "        total_seen = 0\n",
        "        loss_sum = 0\n",
        "        env.classifier = env.classifier.train()\n",
        "\n",
        "        # Process each batch\n",
        "        for i, (points, target) in tqdm(enumerate(env.trainDataLoader), total=len(env.trainDataLoader), smoothing=0.9):\n",
        "            env.optimizer.zero_grad()\n",
        "\n",
        "            # Prep the point cloud data\n",
        "            points = points.data.numpy()\n",
        "            points = torch.Tensor(points)\n",
        "            points, target = points.float().cuda(), target.long().cuda()\n",
        "            points = points.transpose(2, 1)  # PointNet needs this format\n",
        "\n",
        "            # Forward pass through model\n",
        "            seg_pred, trans_feat = env.classifier(points)\n",
        "            seg_pred = seg_pred.contiguous().view(-1, NUM_CLASSES)\n",
        "\n",
        "            batch_label = target.view(-1, 1)[:, 0].cpu().data.numpy()\n",
        "            target = target.view(-1, 1)[:, 0]\n",
        "\n",
        "            # Calculate loss and update weights\n",
        "            loss = env.criterion(seg_pred, target, trans_feat, env.weights)\n",
        "            loss.backward()\n",
        "            env.optimizer.step()\n",
        "\n",
        "            # Track how we're doing\n",
        "            pred_choice = seg_pred.cpu().data.max(1)[1].numpy()\n",
        "            correct = np.sum(pred_choice == batch_label)\n",
        "            total_correct += correct\n",
        "            total_seen += (args.batch_size * args.npoint)\n",
        "            loss_sum += loss\n",
        "\n",
        "        # Log training results\n",
        "        training_loss = loss_sum / num_batches\n",
        "        training_accuracy = total_correct / float(total_seen)\n",
        "\n",
        "        env.log_string('Training mean loss: %f' % training_loss)\n",
        "        env.log_string('Training accuracy: %f' % training_accuracy)\n",
        "        env.writer.add_scalar('Train loss', training_loss, epoch)\n",
        "        env.writer.add_scalar('Train accuracy', training_accuracy, epoch)\n",
        "\n",
        "        # Save model checkpoints regularly\n",
        "        if epoch % 5 == 0 or epoch == args.epoch - 1:\n",
        "            env.log_string('Save model...')\n",
        "            savepath = str(env.checkpoints_dir) + '/model.pth'\n",
        "            env.log_string('Saving at %s' % savepath)\n",
        "            state = {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': env.classifier.state_dict(),\n",
        "                'optimizer_state_dict': env.optimizer.state_dict(),\n",
        "            }\n",
        "            torch.save(state, savepath)\n",
        "            env.log_string('Saving model....')\n",
        "\n",
        "        # Evaluation phase\n",
        "        if args.eval_after_epoch:\n",
        "            env.log_string('---- EPOCH %03d EVALUATION ----' % (global_epoch + 1))\n",
        "            eval_results = evaluate(env, args, epoch=epoch)\n",
        "\n",
        "            #Log Progress\n",
        "            env.log_string('eval point avg class IoU: %f' % eval_results.mIoU)\n",
        "            env.log_string('eval point avg class acc: %f' % (\n",
        "                eval_results.mean_class_accuracy))\n",
        "\n",
        "            # Show per-class results\n",
        "            iou_per_class_str = '------- IoU --------\\n'\n",
        "            for l in range(NUM_CLASSES):\n",
        "                iou_per_class_str += 'class %s weight: %.3f, IoU: %.3f \\n' % (\n",
        "                    seg_label_to_cat[l] + ' ' * (14 - len(seg_label_to_cat[l])),\n",
        "                    eval_results.labelweights[l - 1],\n",
        "                    eval_results.class_mIoU[l]\n",
        "                )\n",
        "\n",
        "            env.log_string(iou_per_class_str)\n",
        "            env.log_string('Eval mean loss: %f' % eval_results.loss)\n",
        "            env.log_string('Eval accuracy: %f' % eval_results.accuracy)\n",
        "\n",
        "            env.writer.add_scalar('Eval loss', eval_results.loss, epoch)\n",
        "            env.writer.add_scalar('Eval accuracy', eval_results.accuracy, epoch)\n",
        "            env.writer.add_scalar('Eval mIoU', eval_results.mIoU, epoch)\n",
        "\n",
        "            #Save if best model\n",
        "            if eval_results.mIoU >= best_iou:\n",
        "                best_iou = eval_results.mIoU\n",
        "                env.log_string('Save model...')\n",
        "                savepath = str(env.checkpoints_dir) + '/best_model.pth'\n",
        "                env.log_string('Saving at %s' % savepath)\n",
        "                state = {\n",
        "                    'epoch': epoch,\n",
        "                    'class_avg_iou': eval_results.mIoU,\n",
        "                    'model_state_dict': env.classifier.state_dict(),\n",
        "                    'optimizer_state_dict': env.optimizer.state_dict(),\n",
        "                }\n",
        "                torch.save(state, savepath)\n",
        "                env.log_string('Saving model....')\n",
        "            env.log_string('Best mIoU: %f' % best_iou)\n",
        "\n",
        "        env.writer.flush()\n",
        "        global_epoch += 1\n",
        "\n",
        "\n",
        "# Container for all our evaluation metrics\n",
        "class EvalResults:\n",
        "    def __init__(self, mIoU, loss, accuracy, labelweights, mean_class_accuracy, class_mIoU):\n",
        "        self.mIoU = mIoU\n",
        "        self.loss = loss\n",
        "        self.accuracy = accuracy\n",
        "        self.labelweights = labelweights\n",
        "        self.mean_class_accuracy = mean_class_accuracy\n",
        "        self.class_mIoU = class_mIoU\n",
        "\n",
        "\n",
        "def evaluate(env, args, epoch=None):\n",
        "    with torch.no_grad():\n",
        "        # Setup tracking variables\n",
        "        num_batches = len(env.testDataLoader)\n",
        "        total_correct = 0\n",
        "        total_seen = 0\n",
        "        loss_sum = 0\n",
        "        labelweights = np.zeros(NUM_CLASSES)\n",
        "        total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
        "        total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
        "        total_iou_deno_class = [0 for _ in range(NUM_CLASSES)]\n",
        "        env.classifier = env.classifier.eval()  # Switch to eval mode\n",
        "\n",
        "        # Save visualization files every 50 epochs\n",
        "        save_visualization = (epoch is not None) and (epoch % 50 == 0 or epoch == args.epoch - 1)\n",
        "\n",
        "        # Need these lists for visualization\n",
        "        if save_visualization:\n",
        "            all_points = []\n",
        "            all_predictions = []\n",
        "            all_ground_truth = []\n",
        "\n",
        "        # Process test batches\n",
        "        for i, (points, target) in tqdm(enumerate(env.testDataLoader), total=len(env.testDataLoader), smoothing=0.9):\n",
        "            original_points = points.data.numpy()\n",
        "\n",
        "            points = torch.Tensor(original_points)\n",
        "            points, target = points.float().cuda(), target.long().cuda()\n",
        "            points = points.transpose(2, 1)\n",
        "\n",
        "            # Get model predictions\n",
        "            seg_pred, trans_feat = env.classifier(points)\n",
        "            pred_val = seg_pred.contiguous().cpu().data.numpy()\n",
        "            seg_pred = seg_pred.contiguous().view(-1, NUM_CLASSES)\n",
        "\n",
        "            batch_label = target.cpu().data.numpy()\n",
        "            target = target.view(-1, 1)[:, 0]\n",
        "            loss = env.criterion(seg_pred, target, trans_feat, env.weights)\n",
        "            loss_sum += loss\n",
        "            pred_val = np.argmax(pred_val, 2)  # Get class predictions\n",
        "            correct = np.sum((pred_val == batch_label))\n",
        "            total_correct += correct\n",
        "            total_seen += (args.batch_size * args.npoint)\n",
        "            tmp, _ = np.histogram(batch_label, range(NUM_CLASSES + 1))\n",
        "            labelweights += tmp\n",
        "\n",
        "            # Per-class metrics\n",
        "            for l in range(NUM_CLASSES):\n",
        "                total_seen_class[l] += np.sum((batch_label == l))\n",
        "                total_correct_class[l] += np.sum((pred_val == l) & (batch_label == l))\n",
        "                total_iou_deno_class[l] += np.sum(((pred_val == l) | (batch_label == l)))\n",
        "\n",
        "            # Collect visualization data if needed\n",
        "            if save_visualization:\n",
        "                for b in range(original_points.shape[0]):\n",
        "                    # Just grab XYZ coordinates\n",
        "                    batch_points = original_points[b, :, :3]\n",
        "                    batch_pred = pred_val[b]\n",
        "                    batch_gt = batch_label[b]\n",
        "\n",
        "                    all_points.append(batch_points)\n",
        "                    all_predictions.append(batch_pred)\n",
        "                    all_ground_truth.append(batch_gt)\n",
        "\n",
        "        # Save colorized point clouds for visualization\n",
        "        if save_visualization:\n",
        "            vis_dir = os.path.join(str(env.checkpoints_dir), 'visualizations')\n",
        "            os.makedirs(vis_dir, exist_ok=True)\n",
        "\n",
        "            # Combine all the collected data\n",
        "            full_points = np.vstack(all_points)\n",
        "            full_predictions = np.concatenate(all_predictions)\n",
        "            full_ground_truth = np.concatenate(all_ground_truth)\n",
        "\n",
        "            # Save as PLY files that can be viewed in 3D software\n",
        "            pred_filename = os.path.join(vis_dir, f'epoch_{epoch}_full_prediction.ply')\n",
        "            save_classified_pointcloud(full_points, full_predictions, pred_filename)\n",
        "\n",
        "            gt_filename = os.path.join(vis_dir, f'epoch_{epoch}_full_groundtruth.ply')\n",
        "            save_classified_pointcloud(full_points, full_ground_truth, gt_filename)\n",
        "\n",
        "        # Calculate final metrics\n",
        "        labelweights = labelweights.astype(np.float32) / np.sum(labelweights.astype(np.float32))\n",
        "        mIoU = np.mean(np.array(total_correct_class) / (np.array(total_iou_deno_class, dtype=float) + 1e-6))\n",
        "        eval_loss = loss_sum / float(num_batches)\n",
        "        eval_accuracy = total_correct / float(total_seen)\n",
        "        mean_class_accuracy = np.mean(np.array(total_correct_class) / (np.array(total_seen_class, dtype=float) + 1e-6))\n",
        "        class_mIoU = [total_correct_class[l] / float(total_iou_deno_class[l]) for l in range(NUM_CLASSES)]\n",
        "\n",
        "        return EvalResults(mIoU, eval_loss, eval_accuracy, labelweights, mean_class_accuracy, class_mIoU)\n",
        "\n",
        "def main():\n",
        "    # Get the config settings\n",
        "    args = get_args()\n",
        "\n",
        "    # Load dataset paths and their labels\n",
        "    train_paths, trainlabels = modify_paths_train()\n",
        "    test_paths, testlabels = modify_paths_test()\n",
        "\n",
        "    # Use fewer samples in test mode\n",
        "    if args.test_mode:\n",
        "        print(f\"Test mode enabled - using only {args.max_test_samples} samples\")\n",
        "        train_paths = train_paths[:args.max_test_samples]\n",
        "        trainlabels = trainlabels[:args.max_test_samples]\n",
        "        test_paths = test_paths[:args.max_test_samples]\n",
        "        testlabels = testlabels[:args.max_test_samples]\n",
        "\n",
        "    # Make sure our data is valid\n",
        "    if len(train_paths) == len(trainlabels) and len(test_paths) == len(testlabels):\n",
        "        # Setup and run training\n",
        "        env = create_environment(args, train_paths, test_paths, trainlabels, testlabels)\n",
        "        train(env, args)\n",
        "        close_environment(env)\n",
        "    else:\n",
        "        # Something's wrong with the data\n",
        "        raise Exception(\"The list of labels for the train and test data do not match lengths.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "FZ8pcQlfCi1I",
        "outputId": "98fed6c1-5646-4d78-84ad-13b172430ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Model:PARAMETER ...\n",
            "INFO:Model:Namespace(data_path='/content/drive/MyDrive/3dgs/datasets', model='pointnet2_sem_seg', dataset_type='3DGS', batch_size=8, epoch=200, learning_rate=0.003, gpu='0', optimizer='Adam', log_dir='epochs250_learningrate_003_bs32_v027_001_4096', weight_decay_rate=0.0001, npoint=4096, lr_step_size=5, lr_decay=0.95, eval_after_epoch=True, sampling='uniform', test_mode=True, max_test_samples=200, extra_features=[<data_utils.extra_feature.ExtraFeature object at 0x7d87e6c9ca50>, <data_utils.extra_feature.ExtraFeature object at 0x7d87e6f57c50>, <data_utils.extra_feature.ExtraFeature object at 0x7d87e6f553d0>])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test mode enabled - using only 200 samples\n",
            "PARAMETER ...\n",
            "Namespace(data_path='/content/drive/MyDrive/3dgs/datasets', model='pointnet2_sem_seg', dataset_type='3DGS', batch_size=8, epoch=200, learning_rate=0.003, gpu='0', optimizer='Adam', log_dir='epochs250_learningrate_003_bs32_v027_001_4096', weight_decay_rate=0.0001, npoint=4096, lr_step_size=5, lr_decay=0.95, eval_after_epoch=True, sampling='uniform', test_mode=True, max_test_samples=200, extra_features=[<data_utils.extra_feature.ExtraFeature object at 0x7d87e6c9ca50>, <data_utils.extra_feature.ExtraFeature object at 0x7d87e6f57c50>, <data_utils.extra_feature.ExtraFeature object at 0x7d87e6f553d0>])\n",
            "start loading training data ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 3/200 [00:00<00:07, 24.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0001/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0002/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0003/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0004/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0005/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0006/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 12/200 [00:00<00:05, 34.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0007/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0008/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0009/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0010/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0011/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0012/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0013/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0014/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 21/200 [00:00<00:05, 35.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0015/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0016/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0017/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0018/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0019/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0020/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0021/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0022/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 25/200 [00:00<00:05, 32.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0023/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0024/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0025/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0026/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0027/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0028/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▋        | 33/200 [00:00<00:04, 33.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0029/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0030/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0031/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0032/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0033/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0034/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0035/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0036/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0037/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 42/200 [00:01<00:04, 36.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0038/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0039/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0040/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0041/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0042/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0043/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0044/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:01<00:04, 32.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0045/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0046/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0047/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0048/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0049/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0050/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0051/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 55/200 [00:01<00:04, 33.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0052/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0053/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0054/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0055/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0056/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0057/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0058/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0059/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 63/200 [00:01<00:03, 34.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0060/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0061/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0062/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0063/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0064/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0065/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0066/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0067/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 72/200 [00:02<00:03, 37.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0068/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0069/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0070/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0071/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0072/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0073/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0074/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0075/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 80/200 [00:02<00:03, 34.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0076/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0077/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0078/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0079/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0080/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0081/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0082/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 84/200 [00:02<00:03, 32.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0083/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0084/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0085/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0086/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0087/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0088/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 92/200 [00:02<00:03, 31.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0089/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0090/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0091/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0092/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0093/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0094/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0095/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [00:02<00:02, 33.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0096/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0097/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0098/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0099/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0100/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0101/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0102/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0103/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0104/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 108/200 [00:03<00:03, 29.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0105/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0106/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0001/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0002/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0003/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 112/200 [00:03<00:03, 28.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0004/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0005/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0006/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0007/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0008/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0009/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 118/200 [00:03<00:03, 22.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0010/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0011/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0012/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0013/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 124/200 [00:03<00:03, 23.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0014/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0015/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0016/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0017/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0018/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0019/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▎   | 127/200 [00:04<00:03, 23.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0020/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0021/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0022/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0023/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0024/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▋   | 133/200 [00:04<00:02, 24.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0025/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0026/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0027/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0028/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0029/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 139/200 [00:04<00:02, 23.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0030/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0031/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0032/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0033/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0034/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 142/200 [00:04<00:02, 24.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0035/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0036/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0037/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0038/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0039/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 148/200 [00:05<00:02, 22.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0040/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0041/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0042/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0043/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0044/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 154/200 [00:05<00:01, 24.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0045/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0046/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0047/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0048/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0049/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0050/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 160/200 [00:05<00:01, 24.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0051/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0052/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0053/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0054/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0055/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0056/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 166/200 [00:05<00:01, 22.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0057/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0058/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0059/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0060/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0061/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 169/200 [00:05<00:01, 22.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0062/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0063/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0064/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0065/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0066/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 172/200 [00:19<00:37,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0067/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 173/200 [00:23<00:47,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0068/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0069/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 175/200 [00:32<01:01,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0070/point_cloud/iteration_15000/point_cloud.ply\n",
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0071/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 177/200 [00:42<01:12,  3.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0072/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 178/200 [00:47<01:14,  3.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0073/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 179/200 [00:51<01:16,  3.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0074/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 180/200 [00:55<01:12,  3.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0075/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 181/200 [01:00<01:12,  3.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0076/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 182/200 [01:04<01:09,  3.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0077/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 183/200 [01:10<01:19,  4.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0078/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 184/200 [01:15<01:15,  4.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0079/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▎| 185/200 [01:20<01:08,  4.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0080/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 186/200 [01:24<01:03,  4.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0081/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 187/200 [01:29<01:01,  4.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0082/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 188/200 [01:34<00:55,  4.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0083/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 189/200 [01:39<00:54,  4.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0084/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 190/200 [01:44<00:48,  4.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0085/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 191/200 [01:49<00:43,  4.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0086/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 192/200 [01:53<00:36,  4.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0087/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▋| 193/200 [01:58<00:33,  4.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0088/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 194/200 [02:02<00:26,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0089/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 195/200 [02:06<00:22,  4.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0090/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 196/200 [02:10<00:17,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0091/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 197/200 [02:15<00:13,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0092/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 198/200 [02:20<00:09,  4.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0093/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 199/200 [02:25<00:04,  4.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0094/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:29<00:00,  1.34it/s]\n",
            "/content/drive/MyDrive/3dgs/datasets/base_dataset.py:31: RuntimeWarning: divide by zero encountered in divide\n",
            "  self.label_weights = np.power(np.amax(label_weights) / label_weights, 1 / 3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 200 models.\n",
            "start loading test data ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0107/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/200 [00:03<12:18,  3.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0108/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 2/200 [00:07<12:16,  3.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0109/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 3/200 [00:10<11:27,  3.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0110/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 4/200 [00:14<12:07,  3.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0111/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▎         | 5/200 [00:17<11:30,  3.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0112/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 6/200 [00:26<17:06,  5.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0113/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 7/200 [00:31<16:25,  5.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0114/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 8/200 [00:35<15:08,  4.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0115/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 9/200 [00:41<16:25,  5.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0116/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 10/200 [00:45<14:56,  4.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0117/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 11/200 [00:48<13:46,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0118/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 12/200 [00:53<14:22,  4.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0119/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 13/200 [00:57<13:39,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0120/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 14/200 [01:01<13:27,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0121/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 15/200 [01:06<13:53,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0122/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 16/200 [01:10<12:59,  4.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0123/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 17/200 [01:14<12:38,  4.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0124/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 18/200 [01:19<13:07,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0125/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 19/200 [01:23<13:05,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0126/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 20/200 [01:27<12:21,  4.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0127/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 21/200 [01:31<12:23,  4.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0128/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 22/200 [01:34<11:46,  3.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0129/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 23/200 [01:40<13:04,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0130/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 24/200 [01:44<13:03,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0131/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 25/200 [01:48<11:52,  4.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0132/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 26/200 [01:52<12:25,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0133/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 27/200 [01:57<12:28,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0134/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 28/200 [02:02<13:13,  4.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0135/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 29/200 [02:05<12:02,  4.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0136/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 30/200 [02:09<11:17,  3.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0137/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 31/200 [02:14<12:25,  4.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0138/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 32/200 [02:18<11:26,  4.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0139/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▋        | 33/200 [02:22<11:31,  4.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0140/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 34/200 [02:26<11:20,  4.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0141/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 35/200 [02:30<11:08,  4.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0142/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 36/200 [02:33<10:37,  3.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0143/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 37/200 [02:37<10:25,  3.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0144/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 38/200 [02:41<10:34,  3.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0145/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 39/200 [02:45<10:51,  4.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0146/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 40/200 [02:49<10:05,  3.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0147/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 41/200 [02:53<10:10,  3.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0148/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 42/200 [02:57<10:15,  3.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0149/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 43/200 [03:01<10:17,  3.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0150/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 44/200 [03:04<09:48,  3.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0151/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▎       | 45/200 [03:11<11:55,  4.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0152/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 46/200 [03:15<11:18,  4.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0153/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 47/200 [03:18<10:42,  4.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0154/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 48/200 [03:23<10:57,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0155/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 49/200 [03:26<10:14,  4.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bathtub, path: /content/drive/MyDrive/3dgs/datasets/bathtub/bathtub_0156/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 50/200 [03:30<09:46,  3.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0516/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 51/200 [03:37<11:45,  4.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0517/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 52/200 [03:40<10:49,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0518/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 53/200 [03:44<10:40,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0519/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 54/200 [03:50<11:12,  4.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0520/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 55/200 [03:53<10:26,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0521/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 56/200 [03:58<10:29,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0522/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 57/200 [04:03<10:52,  4.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0523/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 58/200 [04:08<11:24,  4.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0524/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 59/200 [04:12<10:56,  4.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0525/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 60/200 [04:18<11:46,  5.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0526/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 61/200 [04:23<11:08,  4.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0527/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 62/200 [04:28<11:12,  4.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0528/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 63/200 [04:33<11:07,  4.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0529/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 64/200 [04:38<11:07,  4.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0530/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▎      | 65/200 [04:43<11:13,  4.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0531/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 66/200 [04:48<11:12,  5.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0532/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 67/200 [04:52<10:46,  4.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0533/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 68/200 [04:57<10:20,  4.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0534/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 69/200 [05:01<10:12,  4.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0535/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 70/200 [05:06<10:28,  4.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0536/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 71/200 [05:12<10:58,  5.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0537/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 72/200 [05:15<09:40,  4.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0538/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▋      | 73/200 [05:21<10:00,  4.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0539/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 74/200 [05:26<10:30,  5.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0540/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 75/200 [05:30<09:57,  4.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0541/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 76/200 [05:35<09:45,  4.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0542/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 77/200 [05:39<09:21,  4.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0543/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 78/200 [05:44<09:16,  4.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0544/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 79/200 [05:47<08:36,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0545/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 80/200 [05:53<09:38,  4.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0546/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 81/200 [05:57<09:04,  4.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0547/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 82/200 [06:02<08:44,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0548/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 83/200 [06:06<08:46,  4.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0549/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 84/200 [06:11<08:45,  4.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0550/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▎     | 85/200 [06:17<09:24,  4.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0551/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 86/200 [06:21<09:02,  4.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0552/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▎     | 87/200 [06:25<08:36,  4.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0553/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 88/200 [06:29<08:17,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0554/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 89/200 [06:34<08:18,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0555/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 90/200 [06:39<08:21,  4.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0556/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 91/200 [06:43<08:05,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0557/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 92/200 [06:47<07:50,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0558/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▋     | 93/200 [06:51<07:42,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0559/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 94/200 [06:56<07:53,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0560/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 95/200 [07:00<07:32,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0561/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 96/200 [07:04<07:32,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0562/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 97/200 [07:09<07:25,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0563/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 98/200 [07:14<07:39,  4.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0564/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████▉     | 99/200 [07:18<07:24,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0565/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 100/200 [07:22<07:25,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0566/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 101/200 [07:26<07:11,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0567/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 102/200 [07:32<07:39,  4.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0568/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 103/200 [07:36<07:15,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0569/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 104/200 [07:41<07:17,  4.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0570/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▎    | 105/200 [07:47<08:07,  5.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0571/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 106/200 [07:52<07:50,  5.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0572/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▎    | 107/200 [07:56<07:32,  4.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0573/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 108/200 [08:01<07:19,  4.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0574/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 109/200 [08:06<07:22,  4.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0575/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 110/200 [08:11<07:22,  4.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0576/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 111/200 [08:17<07:48,  5.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0577/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 112/200 [08:21<07:11,  4.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0578/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 113/200 [08:26<06:56,  4.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0579/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 114/200 [08:30<06:47,  4.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0580/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▊    | 115/200 [08:36<06:55,  4.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0581/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 116/200 [08:39<06:16,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0582/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 117/200 [08:45<06:35,  4.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0583/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 118/200 [08:50<06:37,  4.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0584/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 119/200 [08:56<07:03,  5.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0585/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 120/200 [09:01<06:55,  5.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0586/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 121/200 [09:05<06:28,  4.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0587/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 122/200 [09:10<06:21,  4.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0588/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 123/200 [09:15<06:24,  4.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0589/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 124/200 [09:19<06:03,  4.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0590/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 125/200 [09:23<05:39,  4.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0591/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 126/200 [09:29<05:48,  4.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0592/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▎   | 127/200 [09:33<05:48,  4.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0593/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 128/200 [09:41<06:38,  5.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0594/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 129/200 [09:45<06:11,  5.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0595/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 130/200 [09:49<05:44,  4.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0596/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 131/200 [09:55<05:42,  4.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0597/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 132/200 [09:59<05:22,  4.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0598/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▋   | 133/200 [10:04<05:29,  4.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0599/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 134/200 [10:08<05:06,  4.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0600/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 135/200 [10:13<05:06,  4.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0601/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 136/200 [10:18<05:04,  4.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0602/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 137/200 [10:23<05:06,  4.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0603/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 138/200 [10:28<05:00,  4.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0604/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 139/200 [10:33<05:09,  5.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0605/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 140/200 [10:38<05:00,  5.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0606/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 141/200 [10:44<05:06,  5.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0607/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 142/200 [10:49<04:52,  5.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0608/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 143/200 [10:55<05:06,  5.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0609/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 144/200 [10:59<04:50,  5.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0610/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▎  | 145/200 [11:04<04:41,  5.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0611/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 146/200 [11:08<04:10,  4.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0612/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 147/200 [11:13<04:18,  4.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0613/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 148/200 [11:18<04:05,  4.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0614/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 149/200 [11:25<04:33,  5.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: bed, path: /content/drive/MyDrive/3dgs/datasets/bed/bed_0615/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 150/200 [11:29<04:14,  5.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0890/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 151/200 [11:32<03:35,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0891/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 152/200 [11:35<03:18,  4.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0892/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 153/200 [11:38<02:59,  3.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0893/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 154/200 [11:42<02:57,  3.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0894/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 155/200 [11:45<02:43,  3.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0895/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 156/200 [11:49<02:36,  3.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0896/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 157/200 [11:53<02:35,  3.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0897/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 158/200 [11:56<02:25,  3.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0898/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 159/200 [11:59<02:25,  3.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0899/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 160/200 [12:03<02:21,  3.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0900/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 161/200 [12:07<02:21,  3.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0901/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 162/200 [12:11<02:22,  3.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0902/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 163/200 [12:15<02:24,  3.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0903/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 164/200 [12:20<02:29,  4.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0904/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▎ | 165/200 [12:27<02:52,  4.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0905/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 166/200 [12:30<02:27,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0906/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 167/200 [12:34<02:22,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0907/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 168/200 [12:37<02:04,  3.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0908/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 169/200 [12:40<01:54,  3.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0909/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 170/200 [12:43<01:47,  3.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0910/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 171/200 [12:47<01:43,  3.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0911/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 172/200 [12:51<01:41,  3.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0912/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 173/200 [12:55<01:41,  3.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0913/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 174/200 [12:59<01:43,  3.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0914/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 175/200 [13:03<01:39,  3.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0915/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 176/200 [13:06<01:28,  3.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0916/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 177/200 [13:12<01:37,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0917/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 178/200 [13:15<01:26,  3.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0918/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 179/200 [13:18<01:19,  3.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0919/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 180/200 [13:23<01:22,  4.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0920/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 181/200 [13:27<01:14,  3.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0921/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 182/200 [13:30<01:06,  3.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0922/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 183/200 [13:34<01:05,  3.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0923/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 184/200 [13:37<00:58,  3.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0924/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▎| 185/200 [13:40<00:52,  3.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0925/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 186/200 [13:43<00:45,  3.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0926/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 187/200 [13:47<00:45,  3.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0927/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 188/200 [13:51<00:42,  3.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0928/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 189/200 [13:53<00:35,  3.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0929/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 190/200 [13:57<00:32,  3.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0930/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 191/200 [14:01<00:33,  3.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0931/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 192/200 [14:05<00:30,  3.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0932/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▋| 193/200 [14:09<00:26,  3.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0933/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 194/200 [14:13<00:23,  3.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0934/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 195/200 [14:18<00:20,  4.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0935/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 196/200 [14:22<00:16,  4.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0936/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 197/200 [14:25<00:11,  3.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0937/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 198/200 [14:29<00:07,  3.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0938/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 199/200 [14:32<00:03,  3.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classname: chair, path: /content/drive/MyDrive/3dgs/datasets/chair/chair_0939/point_cloud/iteration_15000/point_cloud.ply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [14:36<00:00,  4.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 200 models.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Model:The number of training data is: 49\n",
            "INFO:Model:The number of test data is: 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of training data is: 49\n",
            "The number of test data is: 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Model:Use pretrain model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use pretrain model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Model:**** Epoch 1 (72/200) ****\n",
            "INFO:Model:Learning rate:0.001463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**** Epoch 1 (72/200) ****\n",
            "Learning rate:0.001463\n",
            "BN momentum updated to: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:44<00:00,  7.39s/it]\n",
            "INFO:Model:Training mean loss: 5.004868\n",
            "INFO:Model:Training accuracy: 0.384608\n",
            "INFO:Model:---- EPOCH 001 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mean loss: 5.004868\n",
            "Training accuracy: 0.384608\n",
            "---- EPOCH 001 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:50<00:00,  8.37s/it]\n",
            "<ipython-input-23-b3cf34c65e41>:238: RuntimeWarning: invalid value encountered in divide\n",
            "  class_mIoU = [total_correct_class[l] / float(total_iou_deno_class[l]) for l in range(NUM_CLASSES)]\n",
            "INFO:Model:eval point avg class IoU: 0.237834\n",
            "INFO:Model:eval point avg class acc: 0.253170\n",
            "INFO:Model:------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.825 \n",
            "class bed            weight: 0.210, IoU: 0.852 \n",
            "class chair          weight: 0.539, IoU: 0.701 \n",
            "class desk           weight: 0.251, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: 0.000 \n",
            "class night_stand    weight: 0.000, IoU: 0.000 \n",
            "class sofa           weight: 0.000, IoU: 0.000 \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: 0.000 \n",
            "\n",
            "INFO:Model:Eval mean loss: nan\n",
            "INFO:Model:Eval accuracy: 0.857727\n",
            "INFO:Model:Save model...\n",
            "INFO:Model:Saving at log/sem_seg/epochs250_learningrate_003_bs32_v027_001_4096/checkpoints/best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval point avg class IoU: 0.237834\n",
            "eval point avg class acc: 0.253170\n",
            "------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.825 \n",
            "class bed            weight: 0.210, IoU: 0.852 \n",
            "class chair          weight: 0.539, IoU: 0.701 \n",
            "class desk           weight: 0.251, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: 0.000 \n",
            "class night_stand    weight: 0.000, IoU: 0.000 \n",
            "class sofa           weight: 0.000, IoU: 0.000 \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: 0.000 \n",
            "\n",
            "Eval mean loss: nan\n",
            "Eval accuracy: 0.857727\n",
            "Save model...\n",
            "Saving at log/sem_seg/epochs250_learningrate_003_bs32_v027_001_4096/checkpoints/best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Model:Saving model....\n",
            "INFO:Model:Best mIoU: 0.237834\n",
            "INFO:Model:**** Epoch 2 (73/200) ****\n",
            "INFO:Model:Learning rate:0.001463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model....\n",
            "Best mIoU: 0.237834\n",
            "**** Epoch 2 (73/200) ****\n",
            "Learning rate:0.001463\n",
            "BN momentum updated to: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:41<00:00,  6.99s/it]\n",
            "INFO:Model:Training mean loss: 3.049088\n",
            "INFO:Model:Training accuracy: 0.577489\n",
            "INFO:Model:---- EPOCH 002 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mean loss: 3.049088\n",
            "Training accuracy: 0.577489\n",
            "---- EPOCH 002 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:50<00:00,  8.35s/it]\n",
            "INFO:Model:eval point avg class IoU: 0.194891\n",
            "INFO:Model:eval point avg class acc: 0.221812\n",
            "INFO:Model:------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.723 \n",
            "class bed            weight: 0.208, IoU: 0.773 \n",
            "class chair          weight: 0.540, IoU: 0.453 \n",
            "class desk           weight: 0.252, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: 0.000 \n",
            "class monitor        weight: 0.000, IoU: 0.000 \n",
            "class night_stand    weight: 0.000, IoU: 0.000 \n",
            "class sofa           weight: 0.000, IoU: 0.000 \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: 0.000 \n",
            "\n",
            "INFO:Model:Eval mean loss: nan\n",
            "INFO:Model:Eval accuracy: 0.774740\n",
            "INFO:Model:Best mIoU: 0.237834\n",
            "INFO:Model:**** Epoch 3 (74/200) ****\n",
            "INFO:Model:Learning rate:0.001463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval point avg class IoU: 0.194891\n",
            "eval point avg class acc: 0.221812\n",
            "------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.723 \n",
            "class bed            weight: 0.208, IoU: 0.773 \n",
            "class chair          weight: 0.540, IoU: 0.453 \n",
            "class desk           weight: 0.252, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: 0.000 \n",
            "class monitor        weight: 0.000, IoU: 0.000 \n",
            "class night_stand    weight: 0.000, IoU: 0.000 \n",
            "class sofa           weight: 0.000, IoU: 0.000 \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: 0.000 \n",
            "\n",
            "Eval mean loss: nan\n",
            "Eval accuracy: 0.774740\n",
            "Best mIoU: 0.237834\n",
            "**** Epoch 3 (74/200) ****\n",
            "Learning rate:0.001463\n",
            "BN momentum updated to: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:39<00:00,  6.62s/it]\n",
            "INFO:Model:Training mean loss: 2.040374\n",
            "INFO:Model:Training accuracy: 0.765640\n",
            "INFO:Model:---- EPOCH 003 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mean loss: 2.040374\n",
            "Training accuracy: 0.765640\n",
            "---- EPOCH 003 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:49<00:00,  8.33s/it]\n",
            "INFO:Model:eval point avg class IoU: 0.174751\n",
            "INFO:Model:eval point avg class acc: 0.207624\n",
            "INFO:Model:------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.721 \n",
            "class bed            weight: 0.209, IoU: 0.729 \n",
            "class chair          weight: 0.539, IoU: 0.298 \n",
            "class desk           weight: 0.251, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: 0.000 \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: 0.000 \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: 0.000 \n",
            "\n",
            "INFO:Model:Eval mean loss: nan\n",
            "INFO:Model:Eval accuracy: 0.755371\n",
            "INFO:Model:Best mIoU: 0.237834\n",
            "INFO:Model:**** Epoch 4 (75/200) ****\n",
            "INFO:Model:Learning rate:0.001463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval point avg class IoU: 0.174751\n",
            "eval point avg class acc: 0.207624\n",
            "------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.721 \n",
            "class bed            weight: 0.209, IoU: 0.729 \n",
            "class chair          weight: 0.539, IoU: 0.298 \n",
            "class desk           weight: 0.251, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: 0.000 \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: 0.000 \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: 0.000 \n",
            "\n",
            "Eval mean loss: nan\n",
            "Eval accuracy: 0.755371\n",
            "Best mIoU: 0.237834\n",
            "**** Epoch 4 (75/200) ****\n",
            "Learning rate:0.001463\n",
            "BN momentum updated to: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:42<00:00,  7.12s/it]\n",
            "INFO:Model:Training mean loss: 1.370528\n",
            "INFO:Model:Training accuracy: 0.837779\n",
            "INFO:Model:---- EPOCH 004 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mean loss: 1.370528\n",
            "Training accuracy: 0.837779\n",
            "---- EPOCH 004 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:49<00:00,  8.33s/it]\n",
            "INFO:Model:eval point avg class IoU: 0.156008\n",
            "INFO:Model:eval point avg class acc: 0.196169\n",
            "INFO:Model:------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.710 \n",
            "class bed            weight: 0.208, IoU: 0.712 \n",
            "class chair          weight: 0.542, IoU: 0.137 \n",
            "class desk           weight: 0.251, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: 0.000 \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: 0.000 \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: 0.000 \n",
            "\n",
            "INFO:Model:Eval mean loss: nan\n",
            "INFO:Model:Eval accuracy: 0.730738\n",
            "INFO:Model:Best mIoU: 0.237834\n",
            "INFO:Model:**** Epoch 5 (76/200) ****\n",
            "INFO:Model:Learning rate:0.001390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval point avg class IoU: 0.156008\n",
            "eval point avg class acc: 0.196169\n",
            "------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.710 \n",
            "class bed            weight: 0.208, IoU: 0.712 \n",
            "class chair          weight: 0.542, IoU: 0.137 \n",
            "class desk           weight: 0.251, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: 0.000 \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: 0.000 \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: 0.000 \n",
            "\n",
            "Eval mean loss: nan\n",
            "Eval accuracy: 0.730738\n",
            "Best mIoU: 0.237834\n",
            "**** Epoch 5 (76/200) ****\n",
            "Learning rate:0.001390\n",
            "BN momentum updated to: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:43<00:00,  7.27s/it]\n",
            "INFO:Model:Training mean loss: 0.841207\n",
            "INFO:Model:Training accuracy: 0.879878\n",
            "INFO:Model:Save model...\n",
            "INFO:Model:Saving at log/sem_seg/epochs250_learningrate_003_bs32_v027_001_4096/checkpoints/model.pth\n",
            "INFO:Model:Saving model....\n",
            "INFO:Model:---- EPOCH 005 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mean loss: 0.841207\n",
            "Training accuracy: 0.879878\n",
            "Save model...\n",
            "Saving at log/sem_seg/epochs250_learningrate_003_bs32_v027_001_4096/checkpoints/model.pth\n",
            "Saving model....\n",
            "---- EPOCH 005 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:49<00:00,  8.27s/it]\n",
            "INFO:Model:eval point avg class IoU: 0.154428\n",
            "INFO:Model:eval point avg class acc: 0.194764\n",
            "INFO:Model:------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.748 \n",
            "class bed            weight: 0.208, IoU: 0.705 \n",
            "class chair          weight: 0.541, IoU: 0.092 \n",
            "class desk           weight: 0.251, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: 0.000 \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: 0.000 \n",
            "\n",
            "INFO:Model:Eval mean loss: nan\n",
            "INFO:Model:Eval accuracy: 0.731003\n",
            "INFO:Model:Best mIoU: 0.237834\n",
            "INFO:Model:**** Epoch 6 (77/200) ****\n",
            "INFO:Model:Learning rate:0.001390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval point avg class IoU: 0.154428\n",
            "eval point avg class acc: 0.194764\n",
            "------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.748 \n",
            "class bed            weight: 0.208, IoU: 0.705 \n",
            "class chair          weight: 0.541, IoU: 0.092 \n",
            "class desk           weight: 0.251, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: 0.000 \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: 0.000 \n",
            "\n",
            "Eval mean loss: nan\n",
            "Eval accuracy: 0.731003\n",
            "Best mIoU: 0.237834\n",
            "**** Epoch 6 (77/200) ****\n",
            "Learning rate:0.001390\n",
            "BN momentum updated to: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:40<00:00,  6.81s/it]\n",
            "INFO:Model:Training mean loss: 0.379777\n",
            "INFO:Model:Training accuracy: 0.932205\n",
            "INFO:Model:---- EPOCH 006 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mean loss: 0.379777\n",
            "Training accuracy: 0.932205\n",
            "---- EPOCH 006 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:50<00:00,  8.37s/it]\n",
            "INFO:Model:eval point avg class IoU: 0.151991\n",
            "INFO:Model:eval point avg class acc: 0.190910\n",
            "INFO:Model:------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.743 \n",
            "class bed            weight: 0.210, IoU: 0.692 \n",
            "class chair          weight: 0.540, IoU: 0.085 \n",
            "class desk           weight: 0.250, IoU: nan \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: 0.000 \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: 0.000 \n",
            "\n",
            "INFO:Model:Eval mean loss: nan\n",
            "INFO:Model:Eval accuracy: 0.719950\n",
            "INFO:Model:Best mIoU: 0.237834\n",
            "INFO:Model:**** Epoch 7 (78/200) ****\n",
            "INFO:Model:Learning rate:0.001390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval point avg class IoU: 0.151991\n",
            "eval point avg class acc: 0.190910\n",
            "------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.743 \n",
            "class bed            weight: 0.210, IoU: 0.692 \n",
            "class chair          weight: 0.540, IoU: 0.085 \n",
            "class desk           weight: 0.250, IoU: nan \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: 0.000 \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: 0.000 \n",
            "\n",
            "Eval mean loss: nan\n",
            "Eval accuracy: 0.719950\n",
            "Best mIoU: 0.237834\n",
            "**** Epoch 7 (78/200) ****\n",
            "Learning rate:0.001390\n",
            "BN momentum updated to: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:40<00:00,  6.68s/it]\n",
            "INFO:Model:Training mean loss: 0.327003\n",
            "INFO:Model:Training accuracy: 0.932200\n",
            "INFO:Model:---- EPOCH 007 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mean loss: 0.327003\n",
            "Training accuracy: 0.932200\n",
            "---- EPOCH 007 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:49<00:00,  8.33s/it]\n",
            "INFO:Model:eval point avg class IoU: 0.142602\n",
            "INFO:Model:eval point avg class acc: 0.182831\n",
            "INFO:Model:------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.772 \n",
            "class bed            weight: 0.210, IoU: 0.653 \n",
            "class chair          weight: 0.539, IoU: 0.001 \n",
            "class desk           weight: 0.251, IoU: nan \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: nan \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: nan \n",
            "\n",
            "INFO:Model:Eval mean loss: nan\n",
            "INFO:Model:Eval accuracy: 0.699748\n",
            "INFO:Model:Best mIoU: 0.237834\n",
            "INFO:Model:**** Epoch 8 (79/200) ****\n",
            "INFO:Model:Learning rate:0.001390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval point avg class IoU: 0.142602\n",
            "eval point avg class acc: 0.182831\n",
            "------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.772 \n",
            "class bed            weight: 0.210, IoU: 0.653 \n",
            "class chair          weight: 0.539, IoU: 0.001 \n",
            "class desk           weight: 0.251, IoU: nan \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: nan \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: nan \n",
            "\n",
            "Eval mean loss: nan\n",
            "Eval accuracy: 0.699748\n",
            "Best mIoU: 0.237834\n",
            "**** Epoch 8 (79/200) ****\n",
            "Learning rate:0.001390\n",
            "BN momentum updated to: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:41<00:00,  6.89s/it]\n",
            "INFO:Model:Training mean loss: 0.220615\n",
            "INFO:Model:Training accuracy: 0.957357\n",
            "INFO:Model:---- EPOCH 008 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mean loss: 0.220615\n",
            "Training accuracy: 0.957357\n",
            "---- EPOCH 008 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:50<00:00,  8.34s/it]\n",
            "INFO:Model:eval point avg class IoU: 0.124048\n",
            "INFO:Model:eval point avg class acc: 0.150575\n",
            "INFO:Model:------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.789 \n",
            "class bed            weight: 0.210, IoU: 0.452 \n",
            "class chair          weight: 0.540, IoU: 0.000 \n",
            "class desk           weight: 0.250, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: nan \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: nan \n",
            "\n",
            "INFO:Model:Eval mean loss: nan\n",
            "INFO:Model:Eval accuracy: 0.542211\n",
            "INFO:Model:Best mIoU: 0.237834\n",
            "INFO:Model:**** Epoch 9 (80/200) ****\n",
            "INFO:Model:Learning rate:0.001390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval point avg class IoU: 0.124048\n",
            "eval point avg class acc: 0.150575\n",
            "------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.789 \n",
            "class bed            weight: 0.210, IoU: 0.452 \n",
            "class chair          weight: 0.540, IoU: 0.000 \n",
            "class desk           weight: 0.250, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: nan \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: nan \n",
            "\n",
            "Eval mean loss: nan\n",
            "Eval accuracy: 0.542211\n",
            "Best mIoU: 0.237834\n",
            "**** Epoch 9 (80/200) ****\n",
            "Learning rate:0.001390\n",
            "BN momentum updated to: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:41<00:00,  6.93s/it]\n",
            "INFO:Model:Training mean loss: 0.184063\n",
            "INFO:Model:Training accuracy: 0.962672\n",
            "INFO:Model:---- EPOCH 009 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mean loss: 0.184063\n",
            "Training accuracy: 0.962672\n",
            "---- EPOCH 009 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:49<00:00,  8.27s/it]\n",
            "INFO:Model:eval point avg class IoU: 0.119714\n",
            "INFO:Model:eval point avg class acc: 0.143122\n",
            "INFO:Model:------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.773 \n",
            "class bed            weight: 0.209, IoU: 0.424 \n",
            "class chair          weight: 0.540, IoU: 0.000 \n",
            "class desk           weight: 0.251, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: nan \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: nan \n",
            "\n",
            "INFO:Model:Eval mean loss: nan\n",
            "INFO:Model:Eval accuracy: 0.516378\n",
            "INFO:Model:Best mIoU: 0.237834\n",
            "INFO:Model:**** Epoch 10 (81/200) ****\n",
            "INFO:Model:Learning rate:0.001320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval point avg class IoU: 0.119714\n",
            "eval point avg class acc: 0.143122\n",
            "------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.773 \n",
            "class bed            weight: 0.209, IoU: 0.424 \n",
            "class chair          weight: 0.540, IoU: 0.000 \n",
            "class desk           weight: 0.251, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: nan \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: nan \n",
            "\n",
            "Eval mean loss: nan\n",
            "Eval accuracy: 0.516378\n",
            "Best mIoU: 0.237834\n",
            "**** Epoch 10 (81/200) ****\n",
            "Learning rate:0.001320\n",
            "BN momentum updated to: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:43<00:00,  7.30s/it]\n",
            "INFO:Model:Training mean loss: 0.195061\n",
            "INFO:Model:Training accuracy: 0.954514\n",
            "INFO:Model:Save model...\n",
            "INFO:Model:Saving at log/sem_seg/epochs250_learningrate_003_bs32_v027_001_4096/checkpoints/model.pth\n",
            "INFO:Model:Saving model....\n",
            "INFO:Model:---- EPOCH 010 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mean loss: 0.195061\n",
            "Training accuracy: 0.954514\n",
            "Save model...\n",
            "Saving at log/sem_seg/epochs250_learningrate_003_bs32_v027_001_4096/checkpoints/model.pth\n",
            "Saving model....\n",
            "---- EPOCH 010 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:50<00:00,  8.34s/it]\n",
            "INFO:Model:eval point avg class IoU: 0.135072\n",
            "INFO:Model:eval point avg class acc: 0.165670\n",
            "INFO:Model:------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.807 \n",
            "class bed            weight: 0.209, IoU: 0.544 \n",
            "class chair          weight: 0.540, IoU: 0.000 \n",
            "class desk           weight: 0.251, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: nan \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: nan \n",
            "\n",
            "INFO:Model:Eval mean loss: nan\n",
            "INFO:Model:Eval accuracy: 0.619659\n",
            "INFO:Model:Best mIoU: 0.237834\n",
            "INFO:Model:**** Epoch 11 (82/200) ****\n",
            "INFO:Model:Learning rate:0.001320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval point avg class IoU: 0.135072\n",
            "eval point avg class acc: 0.165670\n",
            "------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.807 \n",
            "class bed            weight: 0.209, IoU: 0.544 \n",
            "class chair          weight: 0.540, IoU: 0.000 \n",
            "class desk           weight: 0.251, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: nan \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: nan \n",
            "\n",
            "Eval mean loss: nan\n",
            "Eval accuracy: 0.619659\n",
            "Best mIoU: 0.237834\n",
            "**** Epoch 11 (82/200) ****\n",
            "Learning rate:0.001320\n",
            "BN momentum updated to: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:45<00:00,  7.50s/it]\n",
            "INFO:Model:Training mean loss: 0.112035\n",
            "INFO:Model:Training accuracy: 0.974640\n",
            "INFO:Model:---- EPOCH 011 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mean loss: 0.112035\n",
            "Training accuracy: 0.974640\n",
            "---- EPOCH 011 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:49<00:00,  8.33s/it]\n",
            "INFO:Model:eval point avg class IoU: 0.143788\n",
            "INFO:Model:eval point avg class acc: 0.180555\n",
            "INFO:Model:------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.799 \n",
            "class bed            weight: 0.209, IoU: 0.639 \n",
            "class chair          weight: 0.540, IoU: 0.000 \n",
            "class desk           weight: 0.251, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: nan \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: nan \n",
            "\n",
            "INFO:Model:Eval mean loss: nan\n",
            "INFO:Model:Eval accuracy: 0.695023\n",
            "INFO:Model:Best mIoU: 0.237834\n",
            "INFO:Model:**** Epoch 12 (83/200) ****\n",
            "INFO:Model:Learning rate:0.001320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval point avg class IoU: 0.143788\n",
            "eval point avg class acc: 0.180555\n",
            "------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.799 \n",
            "class bed            weight: 0.209, IoU: 0.639 \n",
            "class chair          weight: 0.540, IoU: 0.000 \n",
            "class desk           weight: 0.251, IoU: 0.000 \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: nan \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: nan \n",
            "\n",
            "Eval mean loss: nan\n",
            "Eval accuracy: 0.695023\n",
            "Best mIoU: 0.237834\n",
            "**** Epoch 12 (83/200) ****\n",
            "Learning rate:0.001320\n",
            "BN momentum updated to: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:42<00:00,  7.14s/it]\n",
            "INFO:Model:Training mean loss: 0.108132\n",
            "INFO:Model:Training accuracy: 0.974274\n",
            "INFO:Model:---- EPOCH 012 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mean loss: 0.108132\n",
            "Training accuracy: 0.974274\n",
            "---- EPOCH 012 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:49<00:00,  8.33s/it]\n",
            "INFO:Model:eval point avg class IoU: 0.147306\n",
            "INFO:Model:eval point avg class acc: 0.188076\n",
            "INFO:Model:------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.804 \n",
            "class bed            weight: 0.210, IoU: 0.669 \n",
            "class chair          weight: 0.539, IoU: 0.000 \n",
            "class desk           weight: 0.251, IoU: nan \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: nan \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: nan \n",
            "\n",
            "INFO:Model:Eval mean loss: nan\n",
            "INFO:Model:Eval accuracy: 0.718201\n",
            "INFO:Model:Best mIoU: 0.237834\n",
            "INFO:Model:**** Epoch 13 (84/200) ****\n",
            "INFO:Model:Learning rate:0.001320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval point avg class IoU: 0.147306\n",
            "eval point avg class acc: 0.188076\n",
            "------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.804 \n",
            "class bed            weight: 0.210, IoU: 0.669 \n",
            "class chair          weight: 0.539, IoU: 0.000 \n",
            "class desk           weight: 0.251, IoU: nan \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: nan \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: nan \n",
            "\n",
            "Eval mean loss: nan\n",
            "Eval accuracy: 0.718201\n",
            "Best mIoU: 0.237834\n",
            "**** Epoch 13 (84/200) ****\n",
            "Learning rate:0.001320\n",
            "BN momentum updated to: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:42<00:00,  7.08s/it]\n",
            "INFO:Model:Training mean loss: 0.122620\n",
            "INFO:Model:Training accuracy: 0.967733\n",
            "INFO:Model:---- EPOCH 013 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mean loss: 0.122620\n",
            "Training accuracy: 0.967733\n",
            "---- EPOCH 013 EVALUATION ----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:50<00:00,  8.46s/it]\n",
            "INFO:Model:eval point avg class IoU: 0.143529\n",
            "INFO:Model:eval point avg class acc: 0.187694\n",
            "INFO:Model:------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.756 \n",
            "class bed            weight: 0.209, IoU: 0.680 \n",
            "class chair          weight: 0.540, IoU: 0.000 \n",
            "class desk           weight: 0.251, IoU: nan \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: nan \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: nan \n",
            "\n",
            "INFO:Model:Eval mean loss: nan\n",
            "INFO:Model:Eval accuracy: 0.718755\n",
            "INFO:Model:Best mIoU: 0.237834\n",
            "INFO:Model:**** Epoch 14 (85/200) ****\n",
            "INFO:Model:Learning rate:0.001320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval point avg class IoU: 0.143529\n",
            "eval point avg class acc: 0.187694\n",
            "------- IoU --------\n",
            "class bathtub        weight: 0.000, IoU: 0.756 \n",
            "class bed            weight: 0.209, IoU: 0.680 \n",
            "class chair          weight: 0.540, IoU: 0.000 \n",
            "class desk           weight: 0.251, IoU: nan \n",
            "class dresser        weight: 0.000, IoU: nan \n",
            "class monitor        weight: 0.000, IoU: nan \n",
            "class night_stand    weight: 0.000, IoU: nan \n",
            "class sofa           weight: 0.000, IoU: nan \n",
            "class table          weight: 0.000, IoU: 0.000 \n",
            "class toilet         weight: 0.000, IoU: nan \n",
            "\n",
            "Eval mean loss: nan\n",
            "Eval accuracy: 0.718755\n",
            "Best mIoU: 0.237834\n",
            "**** Epoch 14 (85/200) ****\n",
            "Learning rate:0.001320\n",
            "BN momentum updated to: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/6 [00:20<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-b3cf34c65e41>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-b3cf34c65e41>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# Setup and run training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mclose_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-b3cf34c65e41>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(env, args)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# Forward pass through model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mseg_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mseg_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/3dgs/models/pointnet2_sem_seg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xyz)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0ml1_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml0_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml0_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0ml2_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0ml3_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml3_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0ml4_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml4_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml3_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml3_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/3dgs/models/pointnet2_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xyz, points)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mnew_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_and_group_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mnew_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_and_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;31m# new_xyz: sampled points position data, [B, npoint, C]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# new_points: sampled points data, [B, npoint, nsample, C+D]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/3dgs/models/pointnet2_utils.py\u001b[0m in \u001b[0;36msample_and_group\u001b[0;34m(npoint, radius, nsample, xyz, points, returnfps)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxyz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mfps_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfarthest_point_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [B, npoint, C]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mnew_xyz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_ball_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_xyz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/3dgs/models/pointnet2_utils.py\u001b[0m in \u001b[0;36mfarthest_point_sample\u001b[0;34m(xyz, npoint)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mcentroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfarthest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mcentroid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxyz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfarthest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcentroid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mdistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1_nlGgzlxcE5SWaBOGG1inlpsHKJgancb",
      "authorship_tag": "ABX9TyMZlieowrVn5dK1ZW1AAiq9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}